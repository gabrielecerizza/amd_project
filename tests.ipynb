{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zlib\n",
    "import sys\n",
    "import mmh3\n",
    "import sympy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import binascii\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2271845060"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = zlib.crc32(b\"It's\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1949946224"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binascii.crc32(b\"It'sa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_res = np.unique([1, 0, 1, 0, 2]).astype(np.int32)\n",
    "np_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int32"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np_res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_res[0].nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_res.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(np_res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"E:\\datasets\\ukraine\\archive\\UkraineCombinedTweetsDeduped_MAR01.csv.gzip\"\n",
    "df = pd.read_csv(filename, compression='gzip', index_col=0,encoding='utf-8', quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149212    It’s all a game and anonymous cowards are runn...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:1].T.loc[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"It’s all    a  game  and anonymous        cowards   are runn...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_white_space(doc: str):\n",
    "    return \" \".join(doc.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It’s all a game and anonymous cowards are runn...'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_white_space(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shingles(doc: str, k: int, hash_f=zlib.crc32):\n",
    "    # mmh3.hash\n",
    "    return np.unique(\n",
    "        [\n",
    "            hash_f(str.encode(doc[i:i+k]))\n",
    "            for i in range(len(doc[:-k+1]))\n",
    "        ]\n",
    "    ).astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.3 * 10 ** 4) / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [00:22<00:00, 44452.46it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, 10**6)):\n",
    "    create_shingles(\n",
    "        doc=\"It’s all a game and anonymous cowards are runn...\",\n",
    "        k=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"It’s all a game and anonymous cowards are runn...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 153455717,  288717149,  295154963,  407118462,  441600444,\n",
       "        532623397,  590033292,  680984586,  776015344,  793221135,\n",
       "        795978601,  818401770, 1026981217, 1160763629, 1401046386,\n",
       "       1482809627, 1628127214, 1650894579, 1781353979, 1804688512,\n",
       "       1820728365, 1864744421, 2042770013, 2074210065, 2198596228,\n",
       "       2246150770, 2325390644, 2385576300, 2429607434, 2725174392,\n",
       "       2834862695, 2898486736, 3044448930, 3192443023, 3241519139,\n",
       "       3273492596, 3379517467, 3451257145, 3511815274, 3595521134,\n",
       "       3664258875, 3812366278, 3890452140, 3904003990, 3994086357,\n",
       "       4083077667], dtype=uint64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_shingles(\n",
    "    doc=\"It’s all a game and anonymous cowards are runn...\",\n",
    "    k=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_prime(n: int):\n",
    "    if n < 2:\n",
    "        return False\n",
    "    for i in range(2, int(np.sqrt(n))+1):\n",
    "        if (n % i) == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "class HashGenerator:\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_rows: int = np.iinfo(np.uint32).max, \n",
    "        prime: int = 4294967387\n",
    "    ) -> None:\n",
    "        assert is_prime(prime)\n",
    "        assert prime > num_rows\n",
    "\n",
    "        self.prime = prime\n",
    "        self.num_rows = num_rows\n",
    "        self.a_set = set()\n",
    "        self.b_set = set()\n",
    "\n",
    "    def next(self):\n",
    "        a = self._generate_coeff(self.a_set)\n",
    "        b = self._generate_coeff(self.b_set)\n",
    "        print(a,b,self.prime)\n",
    "        return lambda row: np.uint32((a * row + b) % self.prime)\n",
    "\n",
    "    def reset(self):\n",
    "        self.a_set = set()\n",
    "        self.b_set = set()\n",
    "\n",
    "    def _generate_coeff(self, coeff_set: set):\n",
    "        while True:\n",
    "            coeff = random.randint(1, self.num_rows)\n",
    "            if coeff not in coeff_set:\n",
    "                coeff_set.add(coeff)\n",
    "                return coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg = HashGenerator(11, prime=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 11 11\n",
      "[0, 7, 3, 10, 6, 2, 9, 5, 1, 8, 4]\n",
      "8 5 11\n",
      "[5, 2, 10, 7, 4, 1, 9, 6, 3, 0, 8]\n",
      "3 3 11\n",
      "[3, 6, 9, 1, 4, 7, 10, 2, 5, 8, 0]\n",
      "10 8 11\n",
      "[8, 7, 6, 5, 4, 3, 2, 1, 0, 10, 9]\n",
      "2 7 11\n",
      "[7, 9, 0, 2, 4, 6, 8, 10, 1, 3, 5]\n",
      "11 6 11\n",
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "4 9 11\n",
      "[9, 2, 6, 10, 3, 7, 0, 4, 8, 1, 5]\n",
      "5 2 11\n",
      "[2, 7, 1, 6, 0, 5, 10, 4, 9, 3, 8]\n",
      "6 4 11\n",
      "[4, 10, 5, 0, 6, 1, 7, 2, 8, 3, 9]\n",
      "1 1 11\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    f = hg.next()\n",
    "    res = []\n",
    "    for j in range(11):\n",
    "        v = f(j)\n",
    "        res.append(v)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int32"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(f(1))\n",
    "type(np.int32(f(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_coeff(coeff_set: set):\n",
    "        while True:\n",
    "            coeff = random.randint(0, 10)\n",
    "            if coeff not in coeff_set:\n",
    "                coeff_set.add(coeff)\n",
    "                print(coeff_set)\n",
    "                return coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 9}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = set(\n",
    "    (0,1,2,3,4,5,6,7)\n",
    ")\n",
    "_generate_coeff(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10**6):\n",
    "    n = random.randint(np.iinfo(np.int32).min, np.iinfo(np.uint32).max * 2)\n",
    "    try:\n",
    "        assert sympy.isprime(n) == is_prime(n)\n",
    "    except Exception as e:\n",
    "        print(n)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 4294967295)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.iinfo(np.uint32).min, np.iinfo(np.uint32).max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2147483648, 2147483647)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.iinfo(np.int32).min, np.iinfo(np.int32).max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_d = {\n",
    "    1: [0,3],\n",
    "    2: [2], \n",
    "    3: [1,3,4],\n",
    "    4: [0,2,3]\n",
    "}\n",
    "h_f = [\n",
    "    lambda row: (row + 1) % 5,\n",
    "    lambda row: (3 * row + 1) % 5\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_signature(docs_dict, hash_functions, num_rows):\n",
    "    signature = np.full(\n",
    "        (len(hash_functions), len(docs_dict)), \n",
    "        fill_value=np.inf\n",
    "    )\n",
    "    for r in range(0, num_rows):\n",
    "        hash_values = [\n",
    "            f(r)\n",
    "            for f in hash_functions\n",
    "        ]\n",
    "        for c, shingles in enumerate(docs_dict.values()):\n",
    "            if r in shingles:\n",
    "                for i, hash_val in enumerate(hash_values):\n",
    "                    if hash_val < signature[i,c]:\n",
    "                        signature[i,c] = hash_val \n",
    "\n",
    "    return signature.astype(np.uint32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 0, 1],\n",
       "       [0, 2, 0, 0]], dtype=uint32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_signature(s_d, h_f, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000000"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 ** 6 * 20 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import symbols, Eq, solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-(-5/2 - sqrt(17)/2)*(3/2 - sqrt(17)/2), -sqrt(17)/2 - 1/2),\n",
       " (-(-5/2 + sqrt(17)/2)*(3/2 + sqrt(17)/2), -1/2 + sqrt(17)/2),\n",
       " (-(-3/2 + sqrt(13)/2)*(sqrt(13)/2 + 5/2), 1/2 + sqrt(13)/2),\n",
       " (-(5/2 - sqrt(13)/2)*(-sqrt(13)/2 - 3/2), 1/2 - sqrt(13)/2)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = symbols('x, y')\n",
    "eq1 = Eq(x+y**2, 4)\n",
    "eq2 = Eq(x**2 + y, 4)\n",
    "\n",
    "sol = solve([eq1, eq2], [x, y])\n",
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7.08184092021857, 2.82412443675489)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 0.5\n",
    "n = 21\n",
    "b, r = symbols(\"b, r\")\n",
    "eq1 = Eq(t, (1 / b) ** (1 / r))\n",
    "eq2 = Eq(b * r, 20)\n",
    "\n",
    "sol = solve([eq1, eq2], [b, r])\n",
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lsh_params(t: float = 0.5, n: int = 20000):\n",
    "    \"\"\"A lower b means that two items must match a higher\n",
    "    number of rows. By taking the floor of b, we favor\n",
    "    more similar pairs.  \n",
    "    \"\"\"\n",
    "    b, r = symbols('b, r')\n",
    "    eq1 = Eq(t, (1 / b) ** (1 / r))\n",
    "    eq2 = Eq(b * r, n)\n",
    "\n",
    "    b, r = solve([eq1, eq2], [b, r])[0]\n",
    "    b = np.floor(b)\n",
    "    r = n // b\n",
    "    return b, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1843, 10)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b, r = find_lsh_params()\n",
    "b, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5054442772569797, 19998.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 / b) ** (1 / r), b * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(2.82412443675489)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_band = np.array(\n",
    "    [\n",
    "        [0, 1, 2, 1, 3, 4, 3],\n",
    "        [1, 2, 3, 2, 5, 2, 5],\n",
    "        [2, 5, 5, 5, 6, 9, 6]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 2, 1, 3, 4, 3],\n",
       "        [1, 2, 3, 2, 5, 2, 5],\n",
       "        [2, 5, 5, 5, 6, 9, 6]]),\n",
       " array([[0, 1, 2],\n",
       "        [1, 2, 5],\n",
       "        [2, 3, 5],\n",
       "        [1, 2, 5],\n",
       "        [3, 5, 6],\n",
       "        [4, 2, 9],\n",
       "        [3, 5, 6]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_band, sig_band.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_band[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[1 2 5]\n",
      "[2 3 5]\n",
      "[1 2 5]\n",
      "[3 5 6]\n",
      "[4 2 9]\n",
      "[3 5 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(1, 2, 5): [1, 3], (3, 5, 6): [4, 6]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "same_columns = defaultdict(list) # column tuple -> list of column indices\n",
    "for c in range(sig_band.shape[1]):\n",
    "    column = sig_band[:,c]\n",
    "    print(column)\n",
    "    same_columns[tuple(column)].append(c)\n",
    "\n",
    "result = dict()\n",
    "for k, values in same_columns.items():\n",
    "    if len(values) >= 2:\n",
    "        result[k] = values\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pairs = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_pp = {\n",
    "    1: [1,2,3,5],\n",
    "    5: [1,3,4,7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 2),\n",
       " (1, 3),\n",
       " (1, 4),\n",
       " (1, 5),\n",
       " (1, 7),\n",
       " (2, 3),\n",
       " (2, 5),\n",
       " (3, 4),\n",
       " (3, 5),\n",
       " (3, 7),\n",
       " (4, 7)}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for values in res_pp.values():\n",
    "    for pair in combinations(values, 2):\n",
    "        candidate_pairs.add(pair) \n",
    "\n",
    "candidate_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8815554 , 0.19033156, 0.65045907, 0.98344192, 0.83240007],\n",
       "       [0.98639081, 0.36002558, 0.08959581, 0.36185758, 0.27775011],\n",
       "       [0.6433477 , 0.45806965, 0.5842526 , 0.18257248, 0.72574896],\n",
       "       [0.93781773, 0.30734384, 0.35787033, 0.21716055, 0.96922147],\n",
       "       [0.60591778, 0.76847611, 0.96451168, 0.98283087, 0.37176911],\n",
       "       [0.85392617, 0.42975794, 0.41769554, 0.37336736, 0.84191298],\n",
       "       [0.99339853, 0.68357936, 0.37979655, 0.35452576, 0.85127038],\n",
       "       [0.41276621, 0.7485736 , 0.44843024, 0.64592836, 0.22233766],\n",
       "       [0.60132698, 0.85486292, 0.35547451, 0.9460243 , 0.53887209],\n",
       "       [0.21929758, 0.13467481, 0.66971984, 0.65247816, 0.47553981]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.random.rand(10,5)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.8815554 , 0.19033156, 0.65045907, 0.98344192, 0.83240007],\n",
       "        [0.98639081, 0.36002558, 0.08959581, 0.36185758, 0.27775011],\n",
       "        [0.6433477 , 0.45806965, 0.5842526 , 0.18257248, 0.72574896],\n",
       "        [0.93781773, 0.30734384, 0.35787033, 0.21716055, 0.96922147]]),\n",
       " array([[0.60591778, 0.76847611, 0.96451168, 0.98283087, 0.37176911],\n",
       "        [0.85392617, 0.42975794, 0.41769554, 0.37336736, 0.84191298],\n",
       "        [0.99339853, 0.68357936, 0.37979655, 0.35452576, 0.85127038]]),\n",
       " array([[0.41276621, 0.7485736 , 0.44843024, 0.64592836, 0.22233766],\n",
       "        [0.60132698, 0.85486292, 0.35547451, 0.9460243 , 0.53887209],\n",
       "        [0.21929758, 0.13467481, 0.66971984, 0.65247816, 0.47553981]])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_split(arr, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = np.array(\n",
    "    [\n",
    "        [1,2,4,4,2,2],\n",
    "        [0,1,3,4,1,1],\n",
    "        [5,2,6,5,2,4],\n",
    "        [4,1,3,4,2,3],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 1, 4; 1, 5; 4, 5; 0, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsh(signature, b):\n",
    "    candidate_pairs = set()\n",
    "    \n",
    "    for band in np.array_split(signature, b):\n",
    "        \n",
    "        # column tuple -> list of column indices having that tuple\n",
    "        same_columns = defaultdict(list) \n",
    "        \n",
    "        for c in range(band.shape[1]):\n",
    "            column = band[:,c]\n",
    "            same_columns[tuple(column)].append(c)\n",
    "\n",
    "        filtered_same_columns = dict()\n",
    "        for k, values in same_columns.items():\n",
    "            if len(values) >= 2:\n",
    "                filtered_same_columns[k] = values\n",
    "\n",
    "        for values in filtered_same_columns.values():\n",
    "            for pair in combinations(values, 2):\n",
    "                candidate_pairs.add(pair)\n",
    "\n",
    "    return candidate_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 3), (1, 4), (1, 5), (4, 5)}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_pairs = lsh(sig, 2)\n",
    "candidate_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(x, y):\n",
    "    numerator = len(set(x).intersection(set(y)))\n",
    "    denominator = len(set(x).union(set(y)))\n",
    "    return numerator / denominator\n",
    "\n",
    "def check_threshold_on_signature(candidate_pairs, signature, t: float = 0.5):\n",
    "    similar_pairs = set()\n",
    "    false_positive_pairs = set()\n",
    "\n",
    "    for (x, y) in candidate_pairs:\n",
    "        x_col = signature[:,x]\n",
    "        y_col = signature[:,y]\n",
    "        similarity = sum(x_col == y_col) / signature.shape[0]\n",
    "        tup = (x, y, similarity)\n",
    "        if similarity >= t:\n",
    "            similar_pairs.add(tup)\n",
    "        else:\n",
    "            false_positive_pairs.add(tup)\n",
    "\n",
    "    return similar_pairs, false_positive_pairs\n",
    "\n",
    "def check_threshold_on_cm(candidate_pairs, docs_dict, t: float = 0.5):\n",
    "    similar_pairs = set()\n",
    "    false_positive_pairs = set()\n",
    "\n",
    "    for (x, y) in candidate_pairs:\n",
    "        similarity = jaccard_similarity(docs_dict[x], docs_dict[y])\n",
    "        tup = (x, y, similarity)\n",
    "        if similarity >= t:\n",
    "            similar_pairs.add(tup)\n",
    "        else:\n",
    "            false_positive_pairs.add(tup)\n",
    "\n",
    "    return similar_pairs, false_positive_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({(1, 4, 0.75)}, {(0, 3, 0.5), (1, 5, 0.5), (4, 5, 0.5)})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_threshold_on_signature(candidate_pairs, sig, t=0.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = {\n",
    "    0: [4, 5, 6, 1],\n",
    "    1: [1, 2, 3, 4],\n",
    "    3: [1, 5, 6, 4],\n",
    "    4: [0, 1, 2, 90],\n",
    "    5: [4, 1, 7, 8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({(0, 3, 1.0)},\n",
       " {(1, 4, 0.3333333333333333),\n",
       "  (1, 5, 0.3333333333333333),\n",
       "  (4, 5, 0.14285714285714285)})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_threshold_on_cm(candidate_pairs, cm, t=0.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = set([1,2,3,4])\n",
    "b = set([1,2,6,5])\n",
    "jaccard_similarity(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Tuple, Set\n",
    "\n",
    "\n",
    "class LSHModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        k: int,\n",
    "        threshold: float,\n",
    "        num_hashes: int,\n",
    "        hash_generator: HashGenerator,\n",
    "        shingle_hash: Callable = zlib.crc32\n",
    "    ) -> None:\n",
    "        self.k = k\n",
    "        self.threshold = threshold\n",
    "        self.num_hashes = num_hashes\n",
    "        self.hash_generator = hash_generator\n",
    "        self.shingle_hash = shingle_hash\n",
    "        self.num_docs = 0\n",
    "        self.docs_dict = dict()\n",
    "        self.candidate_pairs = set()\n",
    "        self.fp_pairs = set()\n",
    "        self.similar_pairs = set()\n",
    "        self.b = -1\n",
    "        self.r = -1\n",
    "\n",
    "    def add_document(self, doc: str) -> None:\n",
    "        shingles = self._create_shingles(\n",
    "            doc, \n",
    "            self.shingle_hash\n",
    "        )\n",
    "        self.docs_dict[self.num_docs] = shingles\n",
    "        self.num_docs += 1\n",
    "\n",
    "    def run(self) -> set[tuple[int, int]]:\n",
    "        self.hash_generator.reset()\n",
    "        hash_functions = [\n",
    "            self.hash_generator.next()\n",
    "            for _ in range(self.num_hashes)\n",
    "        ]\n",
    "        signature = self._build_signature(\n",
    "            self.docs_dict,\n",
    "            self.num_hashes,\n",
    "            hash_functions\n",
    "        )\n",
    "        self.b, self.r = self._find_lsh_params(\n",
    "            self.threshold,\n",
    "            self.num_hashes\n",
    "        )\n",
    "        self.candidate_pairs = self._lsh(\n",
    "            signature,\n",
    "            self.b\n",
    "        )\n",
    "        self.similar_pairs, self.fp_pairs = \\\n",
    "            self._check_threshold_on_signature(\n",
    "                candidate_pairs,\n",
    "                signature,\n",
    "                self.threshold\n",
    "            )\n",
    "        return self.similar_pairs\n",
    "        \n",
    "    def _create_shingles(\n",
    "        self, \n",
    "        doc: str, \n",
    "        hash_f: Callable\n",
    "    ) -> np.ndarray:\n",
    "        # mmh3.hash\n",
    "        return np.unique(\n",
    "            [\n",
    "                hash_f(str.encode(doc[i:i+k]))\n",
    "                for i in range(len(doc[:-k+1]))\n",
    "            ]\n",
    "        ).astype(np.uint32)\n",
    "\n",
    "    def _build_signature(\n",
    "        self,\n",
    "        docs_dict: dict[int, np.ndarray],\n",
    "        num_rows: int, \n",
    "        hash_functions: list[Callable[[np.uint32], np.uint32]]\n",
    "    ) -> np.ndarray:\n",
    "        signature = np.full(\n",
    "            (len(hash_functions), len(docs_dict)), \n",
    "            fill_value=np.inf\n",
    "        )\n",
    "        for r in range(0, num_rows):\n",
    "            hash_values = [\n",
    "                f(r)\n",
    "                for f in hash_functions\n",
    "            ]\n",
    "            for c, shingles in enumerate(docs_dict.values()):\n",
    "                if r in shingles:\n",
    "                    for i, hash_val in enumerate(hash_values):\n",
    "                        if hash_val < signature[i,c]:\n",
    "                            signature[i,c] = hash_val \n",
    "\n",
    "        return signature.astype(np.uint32)\n",
    "\n",
    "    def _find_lsh_params(self, t: int, n: int) -> tuple[int]:\n",
    "        \"\"\"A lower b means that two items must match a higher\n",
    "        number of rows. By taking the floor of b, we favor\n",
    "        more similar pairs.  \n",
    "        \"\"\"\n",
    "        b, r = symbols('b, r')\n",
    "        eq1 = Eq(t, (1 / b) ** (1 / r))\n",
    "        eq2 = Eq(b * r, n)\n",
    "\n",
    "        b, r = solve([eq1, eq2], [b, r])[0]\n",
    "        b = np.floor(b)\n",
    "        r = n // b\n",
    "        return int(b), int(r)\n",
    "\n",
    "    def _lsh(\n",
    "        self, \n",
    "        signature: np.ndarray, \n",
    "        b: int\n",
    "    ) -> set[tuple[int, int]]:\n",
    "        candidate_pairs = set()\n",
    "        \n",
    "        for band in np.array_split(signature, b):\n",
    "            \n",
    "            # column tuple -> list of column indices having that tuple\n",
    "            same_columns = defaultdict(list) \n",
    "            \n",
    "            for c in range(band.shape[1]):\n",
    "                column = band[:,c]\n",
    "                same_columns[tuple(column)].append(c)\n",
    "\n",
    "            filtered_same_columns = dict()\n",
    "            for k, values in same_columns.items():\n",
    "                if len(values) >= 2:\n",
    "                    filtered_same_columns[k] = values\n",
    "\n",
    "            for values in filtered_same_columns.values():\n",
    "                for pair in combinations(values, 2):\n",
    "                    candidate_pairs.add(pair)\n",
    "\n",
    "        return candidate_pairs\n",
    "\n",
    "    def _check_threshold_on_signature(\n",
    "        self, \n",
    "        candidate_pairs: list[tuple[int, int]], \n",
    "        signature: np.ndarray, \n",
    "        t: float\n",
    "    ) -> tuple[set[tuple[int, int, float]]]:\n",
    "        similar_pairs = set()\n",
    "        false_positive_pairs = set()\n",
    "\n",
    "        for (x, y) in candidate_pairs:\n",
    "            x_col = signature[:,x]\n",
    "            y_col = signature[:,y]\n",
    "            similarity = sum(x_col == y_col) / signature.shape[0]\n",
    "            tup = (x, y, similarity)\n",
    "            if similarity >= t:\n",
    "                similar_pairs.add(tup)\n",
    "            else:\n",
    "                false_positive_pairs.add(tup)\n",
    "\n",
    "        return similar_pairs, false_positive_pairs\n",
    "\n",
    "    def check_threshold_on_cm(\n",
    "        self,\n",
    "        candidate_pairs: list[tuple[int, int]], \n",
    "        docs_dict: dict[int, np.ndarray], \n",
    "        t: float\n",
    "    ) -> tuple[set[tuple[int, int, float]]]:\n",
    "        similar_pairs = set()\n",
    "        false_positive_pairs = set()\n",
    "\n",
    "        for (x, y) in candidate_pairs:\n",
    "            similarity = jaccard_similarity(docs_dict[x], docs_dict[y])\n",
    "            tup = (x, y, similarity)\n",
    "            if similarity >= t:\n",
    "                similar_pairs.add(tup)\n",
    "            else:\n",
    "                false_positive_pairs.add(tup)\n",
    "\n",
    "        return similar_pairs, false_positive_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6203445234801195 1.8383839306750887\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import fsolve\n",
    "from math import exp\n",
    "\n",
    "def equations(vars):\n",
    "    x, y = vars\n",
    "    eq1 = x+y**2-4\n",
    "    eq2 = exp(x) + x*y - 3\n",
    "    return [eq1, eq2]\n",
    "\n",
    "x, y =  fsolve(equations, (1, 1))\n",
    "\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.32008145851344 4.48027038726856\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "t = 0.5\n",
    "\n",
    "def equations(vars):\n",
    "    b, r = vars\n",
    "    eq1 = t - (1 / b) ** (1 / r)\n",
    "    eq2 = n - b * r\n",
    "    return [eq1, eq2]\n",
    "\n",
    "b, r =  fsolve(equations, (1, 1))\n",
    "\n",
    "print(b, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.99999999999982"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\projects\\amd\\tests.ipynb Cella 64\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/projects/amd/tests.ipynb#ch0000066?line=7'>8</a>\u001b[0m solution \u001b[39m=\u001b[39m solve([eq1, eq2], [b, r])\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/projects/amd/tests.ipynb#ch0000066?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(solution)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/projects/amd/tests.ipynb#ch0000066?line=9'>10</a>\u001b[0m b, r \u001b[39m=\u001b[39m solution[\u001b[39m0\u001b[39;49m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/amd/tests.ipynb#ch0000066?line=10'>11</a>\u001b[0m b \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfloor(b)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/amd/tests.ipynb#ch0000066?line=11'>12</a>\u001b[0m r \u001b[39m=\u001b[39m n \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m b\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from sympy import *\n",
    "\n",
    "n = 100\n",
    "b, r = symbols('b, r')\n",
    "eq1 = Eq(0.5, (1 / b) ** (1 / r))\n",
    "eq2 = Eq(b * r, n)\n",
    "\n",
    "solution = solve([eq1, eq2], [b, r])\n",
    "print(solution)\n",
    "b, r = solution[0]\n",
    "b = np.floor(b)\n",
    "r = n // b\n",
    "int(b), int(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}22.3200814585134\\\\4.48027038726857\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[22.3200814585134],\n",
       "[4.48027038726857]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b, r = symbols('b, r')\n",
    "nsolve([eq1, eq2], [b, r], [22, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312500000"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50 ** 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15625000000"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50 ** 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser'], exclude=['ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"#standwithukraine️ #ukraineunderattack what's the best policy 62,000 for the future of 🇺🇸🇨🇳 relations over taiwan?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#  # True False\n",
      "standwithukraine️  standwithukraine️ False False\n",
      "#  # True False\n",
      "ukraineunderattack  ukraineunderattack False False\n",
      "what  what False True\n",
      "'s  's False True\n",
      "the  the False True\n",
      "best  best False False\n",
      "policy  policy False False\n",
      "62,000  62,000 False False\n",
      "for  for False True\n",
      "the  the False True\n",
      "future  future False False\n",
      "of  of False True\n",
      "🇺  🇺 False False\n",
      "🇸  🇸 False False\n",
      "🇨  🇨 False False\n",
      "🇳  🇳 False False\n",
      "relations  relations False False\n",
      "over  over False True\n",
      "taiwan  taiwan False False\n",
      "?  ? True False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\gabri\\anaconda3\\envs\\tf_p3.9\\lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "for tok in nlp(doc):\n",
    "    print(tok, tok.pos_, tok.lemma_, tok.is_punct, tok.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================= Pipeline Overview =============================\u001b[0m\n",
      "\n",
      "#   Component         Assigns               Requires   Scores             Retokenizes\n",
      "-   ---------------   -------------------   --------   ----------------   -----------\n",
      "0   tok2vec           doc.tensor                                          False      \n",
      "                                                                                     \n",
      "1   tagger            token.tag                        tag_acc            False      \n",
      "                                                                                     \n",
      "2   parser            token.dep                        dep_uas            False      \n",
      "                      token.head                       dep_las                       \n",
      "                      token.is_sent_start              dep_las_per_type              \n",
      "                      doc.sents                        sents_p                       \n",
      "                                                       sents_r                       \n",
      "                                                       sents_f                       \n",
      "                                                                                     \n",
      "3   attribute_ruler                                                       False      \n",
      "                                                                                     \n",
      "4   lemmatizer        token.lemma                      lemma_acc          False      \n",
      "                                                                                     \n",
      "5   ner               doc.ents                         ents_f             False      \n",
      "                      token.ent_iob                    ents_p                        \n",
      "                      token.ent_type                   ents_r                        \n",
      "                                                       ents_per_type                 \n",
      "\n",
      "✔ No problems found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'summary': {'tok2vec': {'assigns': ['doc.tensor'],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'tagger': {'assigns': ['token.tag'],\n",
       "   'requires': [],\n",
       "   'scores': ['tag_acc'],\n",
       "   'retokenizes': False},\n",
       "  'parser': {'assigns': ['token.dep',\n",
       "    'token.head',\n",
       "    'token.is_sent_start',\n",
       "    'doc.sents'],\n",
       "   'requires': [],\n",
       "   'scores': ['dep_uas',\n",
       "    'dep_las',\n",
       "    'dep_las_per_type',\n",
       "    'sents_p',\n",
       "    'sents_r',\n",
       "    'sents_f'],\n",
       "   'retokenizes': False},\n",
       "  'attribute_ruler': {'assigns': [],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'lemmatizer': {'assigns': ['token.lemma'],\n",
       "   'requires': [],\n",
       "   'scores': ['lemma_acc'],\n",
       "   'retokenizes': False},\n",
       "  'ner': {'assigns': ['doc.ents', 'token.ent_iob', 'token.ent_type'],\n",
       "   'requires': [],\n",
       "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
       "   'retokenizes': False}},\n",
       " 'problems': {'tok2vec': [],\n",
       "  'tagger': [],\n",
       "  'parser': [],\n",
       "  'attribute_ruler': [],\n",
       "  'lemmatizer': [],\n",
       "  'ner': []},\n",
       " 'attrs': {'token.dep': {'assigns': ['parser'], 'requires': []},\n",
       "  'token.tag': {'assigns': ['tagger'], 'requires': []},\n",
       "  'token.is_sent_start': {'assigns': ['parser'], 'requires': []},\n",
       "  'doc.tensor': {'assigns': ['tok2vec'], 'requires': []},\n",
       "  'token.ent_iob': {'assigns': ['ner'], 'requires': []},\n",
       "  'doc.ents': {'assigns': ['ner'], 'requires': []},\n",
       "  'token.head': {'assigns': ['parser'], 'requires': []},\n",
       "  'doc.sents': {'assigns': ['parser'], 'requires': []},\n",
       "  'token.ent_type': {'assigns': ['ner'], 'requires': []},\n",
       "  'token.lemma': {'assigns': ['lemmatizer'], 'requires': []}}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.analyze_pipes(pretty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = \"'𝙂','𝙖''𝙘''𝙙''𝙚 '𝙜''𝙝 '𝙞'𝙣' '𝙤' '𝙧' '𝙨''𝙩'𝙬'\"\n",
    "ss2 = \"нетвойне\"\n",
    "ss3 = \"'𝕋','𝕒''𝕕''𝕖''𝕗''𝕘''𝕙' '𝕟''𝕠''𝕣' '𝕤' '𝕥''𝕩' '𝕮''𝕹'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'T','a''d''e''f''g''h' 'n''o''r' 's' 't''x' 'C''N'\""
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicodedata.normalize('NFKD', ss3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"#\".isprintable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1236360530447794878"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'hello'.__hash__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot convert 'str' object to bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\projects\\amd\\tests.ipynb Cella 78\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/projects/amd/tests.ipynb#ch0000077?line=0'>1</a>\u001b[0m \u001b[39mint\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_bytes(hashlib\u001b[39m.\u001b[39;49msha256(\u001b[39m\"\u001b[39;49m\u001b[39mmy_string\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mencode())\u001b[39m.\u001b[39;49mhexdigest()[:\u001b[39m10\u001b[39;49m], \u001b[39m'\u001b[39;49m\u001b[39mlittle\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot convert 'str' object to bytes"
     ]
    }
   ],
   "source": [
    "int.from_bytes(hashlib.sha256(\"my_string\".encode()).hexdigest()[:10], 'little')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'101001001001110101110111110100'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = bin(int.from_bytes(hashlib.sha256(\"my_string\".encode()).digest(), 'little'))[-30:]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "690445812"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(b, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variable_length_hash(n: int):\n",
    "    def inner_f(s: str):\n",
    "        binary_str = bin(\n",
    "            int.from_bytes(\n",
    "                hashlib.sha256(s.encode()).digest(), \n",
    "                'little'\n",
    "            )\n",
    "        )[-n:]\n",
    "        return int(binary_str, 2)\n",
    "    return inner_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = get_variable_length_hash(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "690445812"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(\"my_string\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('tf_p3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "581cf1c8eaff79be0b011c62368efcaf64eb5b63193a1727e5f23ab81cee7c9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
