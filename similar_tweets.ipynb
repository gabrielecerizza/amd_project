{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADD COLAB BADGE (kida) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()\n",
    "\n",
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle datasets download -d bwandowando/ukraine-russian-crisis-twitter-dataset-1-2-m-rows\n",
    "!unzip ukraine-russian-crisis-twitter-dataset-1-2-m-rows.zip -d dataset\n",
    "!rm ukraine-russian-crisis-twitter-dataset-1-2-m-rows.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import hashlib\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import timeit\n",
    "import unicodedata\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from typing import Callable, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.stats import kendalltau, spearmanr\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load('en_core_web_sm', exclude=['parser', 'ner'])\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_prime(n: int) -> bool:\n",
    "    if n < 2:\n",
    "        return False\n",
    "    for i in range(2, int(np.sqrt(n))+1):\n",
    "        if (n % i) == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def find_closest_prime(n: int) -> int:\n",
    "    \"\"\"Finds the closest prime number higher than input.\"\"\"\n",
    "    while True:\n",
    "        if is_prime(n):\n",
    "            return n\n",
    "        n += 1\n",
    "\n",
    "def get_variable_length_hash(\n",
    "    n_bits: int\n",
    ") -> Callable[[str], int]:\n",
    "    \"\"\"Generates a hash function that takes a string\n",
    "    as input and has 2 ** n_bits integer buckets.\n",
    "    \"\"\"\n",
    "    def inner_f(s: str) -> int:\n",
    "        binary_str = bin(\n",
    "            int.from_bytes(\n",
    "                hashlib.sha256(s.encode()).digest(), \n",
    "                'little'\n",
    "            )\n",
    "        )[-n_bits:]\n",
    "        return int(binary_str, 2)\n",
    "    return inner_f\n",
    "\n",
    "class HashGenerator:\n",
    "    \"\"\"Generator of hash functions of the form:\n",
    "            h(x) = (ax + b) mod c\n",
    "    where x is a row number, a and b are random numbers\n",
    "    smaller than the maximum row number and c is a prime\n",
    "    number higher than the maximum row number.\n",
    "\n",
    "    Note that a and b must be unique for a given signature\n",
    "    matrix.\n",
    "\n",
    "    This approach to hash function generation was suggested\n",
    "    in [1].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_rows : int\n",
    "        Maximum number of rows of the characteristic matrix.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "        [1] http://ethen8181.github.io/machine-learning/clustering_old/text_similarity/text_similarity.html\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_rows: int, \n",
    "    ) -> None:\n",
    "        self.num_rows = num_rows\n",
    "        self.prime = find_closest_prime(num_rows)\n",
    "        self.a_set = set()\n",
    "        self.b_set = set()\n",
    "\n",
    "    def get_num_rows(self) -> int:\n",
    "        return self.num_rows\n",
    "\n",
    "    def next(self) -> Callable[[np.uint32], np.uint32]:\n",
    "        \"\"\"Returns a hash function that takes a row number \n",
    "        as input and returns another row number as output.\n",
    "        \"\"\"\n",
    "        a = self._generate_coeff(self.a_set, self.num_rows)\n",
    "        b = self._generate_coeff(self.b_set, self.num_rows)\n",
    "        return lambda row: np.uint32((a * row + b) % self.prime)\n",
    "\n",
    "    def _generate_coeff(\n",
    "        self, \n",
    "        coeff_set: set[int],\n",
    "        max_val: int\n",
    "    ) -> int:\n",
    "        while True:\n",
    "            coeff = random.randint(1, max_val)\n",
    "            if coeff not in coeff_set:\n",
    "                coeff_set.add(coeff)\n",
    "                return coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_white_space(doc: str) -> str:\n",
    "    return \" \".join(doc.split())\n",
    "\n",
    "def remove_https(doc: str) -> str:\n",
    "    return re.sub(r'https?://[^ ]+', '', doc)\n",
    "\n",
    "def replace_chars(doc: str) -> str:\n",
    "    return doc.replace('&amp;', ' and ')\n",
    "\n",
    "def remove_non_ascii(doc: str) -> str:\n",
    "    \"\"\"Removes non ascii and non printable characters.\n",
    "    We keep cyrillic characters due to the nature\n",
    "    of the dataset.\n",
    "    \"\"\"\n",
    "    cyr_chars = \"АаБбВвГгДдЕеЁёЖжЗзИиЙйКкЛлМмНнОоПпРрСсТтУуФфХхЦцЧчШшЩщЪъЫыЬьЭэЮюЯя\"\n",
    "\n",
    "    res = \"\"\n",
    "    for c in doc:\n",
    "        if (c.isascii() and c.isprintable()) \\\n",
    "            or (c in cyr_chars) or c.isspace():\n",
    "            res += c\n",
    "    return res\n",
    "\n",
    "def strip_accents(doc: str) -> str:\n",
    "    \"\"\"Replaces words with accent with their \n",
    "    counterpart without accent. This also deals with \n",
    "    special characters such as 𝕒, 𝕕, 𝕖, 𝙖, 𝙘, 𝙙. \n",
    "    \"\"\"\n",
    "    return unicodedata.normalize('NFKD', doc)\n",
    "\n",
    "def strip_punctuation(doc: str) -> str:\n",
    "    return re.sub('[' + re.escape(string.punctuation) + ']', '', doc)\n",
    "    \n",
    "def get_lemmatizer( \n",
    "    nlp: spacy.pipeline, \n",
    "    allow_stop_words: bool = False,\n",
    "    allow_punct: bool = False,\n",
    "    allow_numbers: bool = False\n",
    ") -> Callable[[str], str]:\n",
    "    \"\"\"Generates a function that takes a string as\n",
    "    input and returns the string sequence of lemmas\n",
    "    in the input string. Optionally, the generated\n",
    "    function removes stop words, punctuation and\n",
    "    numbers.\n",
    "\n",
    "    Note that numbers are tokens identified as such.\n",
    "    For instance, '62,000' is a number, but 'T-72' is\n",
    "    not.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nlp : spacy.pipeline\n",
    "        Spacy object that carries out the lemmatization.\n",
    "    \n",
    "    allow_stop_words : bool\n",
    "        Boolean value to filter or allow stop words.\n",
    "\n",
    "    allow_punct : bool\n",
    "        Boolean value to filter or allow punctuation.\n",
    "    \n",
    "    allow_numbers : bool\n",
    "        Boolean value to filter or allow numbers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The generated function. \n",
    "    \"\"\"\n",
    "    def inner_f(doc: str) -> str:\n",
    "        return ' '.join(\n",
    "            [\n",
    "                token.lemma_\n",
    "                for token in nlp(doc)\n",
    "                if (not token.is_stop or allow_stop_words) \\\n",
    "                    and (not token.is_punct or allow_punct) \\\n",
    "                    and (token.pos_ != 'NUM' or allow_numbers) \\\n",
    "                    and (not token.pos_ == 'X')\n",
    "            ]\n",
    "        )\n",
    "    return inner_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(\n",
    "    x: np.ndarray, \n",
    "    y: np.ndarray\n",
    ") -> float:\n",
    "    numerator = len(set(x).intersection(set(y)))\n",
    "    denominator = len(set(x).union(set(y)))\n",
    "    return numerator / denominator\n",
    "\n",
    "class LSHModel:\n",
    "    \"\"\"Implementation of LSH model that finds similar pairs\n",
    "    of documents encoded as k-gram shingles.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    k : int\n",
    "        Number of characters in each k-gram.\n",
    "\n",
    "    threshold : float\n",
    "        The similarity value required to consider a\n",
    "        pair as similar.\n",
    "\n",
    "    num_hashes : int\n",
    "        Number of hash functions used to generate the\n",
    "        signature matrix.\n",
    "\n",
    "    shingle_hash_bits : int\n",
    "        Determines the number of buckets of the hash\n",
    "        function that maps each shingle to an integer.\n",
    "\n",
    "    track_shingles : bool\n",
    "        Flag to keep track of the number of different\n",
    "        shingles found in the corpus, as well as the\n",
    "        number of different characters in the shingles.\n",
    "\n",
    "    checkpoint_path : Optional[str]\n",
    "        Path to save and load the state of the model.\n",
    "\n",
    "    Exceptions\n",
    "    ----------\n",
    "    ValueError\n",
    "        If the number of hash functions is higher than the\n",
    "        number of rows of the characteristic matrix (which is\n",
    "        also the number of shingles). This is due to the fact\n",
    "        that the the coefficients 'a' and 'b' of the hash\n",
    "        functions generated by HashGenerator need to be unique\n",
    "        within the given signature matrix.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        k: int,\n",
    "        threshold: float,\n",
    "        num_hashes: int,\n",
    "        shingle_hash_bits: int,\n",
    "        track_shingles: bool = False,\n",
    "        checkpoint_path: Optional[str] = None\n",
    "    ) -> None:\n",
    "        self.k = k\n",
    "        self.threshold = threshold\n",
    "        self.num_hashes = num_hashes\n",
    "        self.shingle_set = set()\n",
    "        self.char_set = set()\n",
    "        self.shingle_hash_bits = shingle_hash_bits\n",
    "        self.shingle_hash = get_variable_length_hash(\n",
    "            shingle_hash_bits\n",
    "        )\n",
    "        self.num_shingles = 2 ** shingle_hash_bits\n",
    "        self.track_shingles = track_shingles\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.num_docs = 0\n",
    "        self.docs_dict = dict()\n",
    "        self.signature = None\n",
    "        self.candidate_pairs = set()\n",
    "        self.fp_pairs = set()\n",
    "        self.similar_pairs = set()\n",
    "        self.b = -1\n",
    "        self.r = -1\n",
    "        self.sig_idx = -1\n",
    "\n",
    "        if self.num_hashes > self.num_shingles:\n",
    "            raise ValueError(\n",
    "                f\"Number of hash functions must be lower than \"\n",
    "                f\"or equal to the number of shingles. Found \"\n",
    "                f\"{self.num_hashes} hash functions and \"\n",
    "                f\"{self.num_shingles} shingles.\"\n",
    "            )\n",
    "\n",
    "    def load_checkpoint(\n",
    "        self,\n",
    "        checkpoint_path: Optional[str] = None\n",
    "    ) -> None:\n",
    "        if checkpoint_path is not None:\n",
    "            self.checkpoint_path = checkpoint_path\n",
    "        if self.checkpoint_path is None:\n",
    "            raise ValueError(\n",
    "                \"Checkpoint path not found\"\n",
    "            )\n",
    "        else:\n",
    "            tup_ls = [\n",
    "                (f'{self.checkpoint_path}/docs_dict.npy', 'docs_dict'),\n",
    "                (f'{self.checkpoint_path}/shingle_set.npy', 'shingle_set'),\n",
    "                (f'{self.checkpoint_path}/char_set.npy', 'char_set'),\n",
    "                (f'{self.checkpoint_path}/signature.npy', 'signature'),\n",
    "                (f'{self.checkpoint_path}/sig_idx.npy', 'sig_idx'),\n",
    "                (f'{self.checkpoint_path}/candidate_pairs.npy', 'candidate_pairs'),\n",
    "                (f'{self.checkpoint_path}/fp_pairs.npy', 'fp_pairs'),\n",
    "                (f'{self.checkpoint_path}/similar_pairs.npy', 'similar_pairs')\n",
    "            ]\n",
    "\n",
    "            for file_path, attr in tup_ls:\n",
    "                if os.path.isfile(file_path):\n",
    "                    if attr in ['signature']:\n",
    "                        setattr(\n",
    "                            self, \n",
    "                            attr, \n",
    "                            np.load(file_path, allow_pickle=True)\n",
    "                        )\n",
    "                    else:\n",
    "                        setattr(\n",
    "                            self, \n",
    "                            attr, \n",
    "                            np.load(file_path, allow_pickle=True).item()\n",
    "                        )\n",
    "                        \n",
    "    def save_checkpoint(\n",
    "        self,\n",
    "        checkpoint_path: Optional[str] = None\n",
    "    ) -> None:\n",
    "        if checkpoint_path is not None:\n",
    "            self.checkpoint_path = checkpoint_path\n",
    "        if self.checkpoint_path is None:\n",
    "            raise ValueError(\n",
    "                \"Checkpoint path not found\"\n",
    "            )\n",
    "        else:\n",
    "            os.makedirs(self.checkpoint_path, exist_ok=True)\n",
    "\n",
    "            tup_ls = [\n",
    "                (f'{self.checkpoint_path}/docs_dict.npy', self.docs_dict),\n",
    "                (f'{self.checkpoint_path}/shingle_set.npy', self.shingle_set),\n",
    "                (f'{self.checkpoint_path}/char_set.npy', self.char_set),\n",
    "                (f'{self.checkpoint_path}/signature.npy', self.signature),\n",
    "                (f'{self.checkpoint_path}/sig_idx.npy', self.sig_idx),\n",
    "                (f'{self.checkpoint_path}/candidate_pairs.npy', self.candidate_pairs),\n",
    "                (f'{self.checkpoint_path}/fp_pairs.npy', self.fp_pairs),\n",
    "                (f'{self.checkpoint_path}/similar_pairs.npy', self.similar_pairs)\n",
    "            ]\n",
    "\n",
    "            for file_path, val in tup_ls:\n",
    "                np.save(file_path, val)\n",
    "\n",
    "    def add_document(\n",
    "        self, \n",
    "        doc: str,\n",
    "        preprocessing_pipeline: Optional[list[Callable[[str], str]]] = None\n",
    "    ) -> None:\n",
    "        \"\"\"Creates shingles from the document given in input and\n",
    "        adds those shingles to the model. Optionally, the document\n",
    "        is preprocessed with a number of functions given in a \n",
    "        pipeline.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        doc : str\n",
    "            String document to be processed.\n",
    "\n",
    "        preprocessing_pipeline : Optional[list[Callable[[str], str]]]\n",
    "            List of functions that take a string and return a string.\n",
    "            This is used to filter stop words, apply lemmatization, etc.\n",
    "        \"\"\"\n",
    "        if preprocessing_pipeline is not None:\n",
    "            for f in preprocessing_pipeline:\n",
    "                doc = f(doc)\n",
    "        shingles = self._create_shingles(\n",
    "            doc, \n",
    "            self.k,\n",
    "            self.track_shingles,\n",
    "            self.shingle_hash\n",
    "        )\n",
    "        self.docs_dict[self.num_docs] = shingles\n",
    "        self.num_docs += 1\n",
    "\n",
    "    def get_similar_pairs(\n",
    "        self,\n",
    "        checkpoint_path: Optional[str] = None,\n",
    "        checkpoint_freq: int = 10000\n",
    "    ) -> set[tuple[tuple[int, int], float]]:\n",
    "        \"\"\"Returns the pairs having an approximated similarity \n",
    "        higher than a fixed threshold. The pairs are provided as \n",
    "        a set of tuples containing the indices of the documents and\n",
    "        their similarity value. \n",
    "        \n",
    "        The approximated similarity measure is the Jaccard\n",
    "        similarity.\n",
    "\n",
    "        This function also saves the false positive pairs identified\n",
    "        after double-checking the signature matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        checkpoint_path : Optional[str]\n",
    "            Path to save and load the state of the model. This is used\n",
    "            when building the signature matrix.\n",
    "\n",
    "        checkpoint_freq : int\n",
    "            Frequency with which the state of the model is saved.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        The set of pairs approximately similar, alongside their \n",
    "        similarity value.\n",
    "        \"\"\"\n",
    "        hg = HashGenerator(self.num_shingles)\n",
    "        hash_functions = [\n",
    "            hg.next()\n",
    "            for _ in range(self.num_hashes)\n",
    "        ]\n",
    "        self.signature = self._build_signature(\n",
    "            self.docs_dict,\n",
    "            self.num_shingles,\n",
    "            hash_functions,\n",
    "            checkpoint_path,\n",
    "            checkpoint_freq\n",
    "        )\n",
    "        self.b, self.r = self._find_lsh_params(\n",
    "            self.threshold,\n",
    "            self.num_hashes\n",
    "        )\n",
    "        self.candidate_pairs = self._lsh(\n",
    "            self.signature,\n",
    "            self.b\n",
    "        )\n",
    "        self.similar_pairs, self.fp_pairs = \\\n",
    "            self._check_threshold_on_signature(\n",
    "                self.candidate_pairs,\n",
    "                self.signature,\n",
    "                self.threshold\n",
    "            )\n",
    "        return self.similar_pairs\n",
    "\n",
    "    def _create_shingles(\n",
    "        self,\n",
    "        doc: str, \n",
    "        k: int,\n",
    "        track_shingles: bool, \n",
    "        hash_f: Callable[[str], int]\n",
    "    ) -> np.ndarray:\n",
    "        res = []\n",
    "\n",
    "        for i in range(len(doc[:-k+1])):\n",
    "            shingle = doc[i:i+k]\n",
    "            if track_shingles:\n",
    "                self.shingle_set.add(shingle)\n",
    "                self.char_set = self.char_set.union(\n",
    "                    set(shingle)\n",
    "                ) \n",
    "            res.append(hash_f(shingle))\n",
    "\n",
    "        return np.unique(res).astype(np.uint32)\n",
    "\n",
    "    def _build_signature(\n",
    "        self,\n",
    "        docs_dict: dict[int, np.ndarray],\n",
    "        num_rows: int, \n",
    "        hash_functions: list[Callable[[np.uint32], np.uint32]],\n",
    "        checkpoint_path: Optional[str] = None,\n",
    "        checkpoint_freq: int = 10000\n",
    "    ) -> np.ndarray:\n",
    "        if checkpoint_path is not None:\n",
    "            self.checkpoint_path = checkpoint_path\n",
    "        if self.checkpoint_path is not None:\n",
    "            os.makedirs(self.checkpoint_path, exist_ok=True)\n",
    "        \n",
    "        sig_path = f'{self.checkpoint_path}/temp_signature.npy'\n",
    "        sig_idx_path = f'{self.checkpoint_path}/temp_sig_idx.npy'\n",
    "        \n",
    "        if self.checkpoint_path is not None and \\\n",
    "            os.path.isfile(sig_path) and \\\n",
    "            os.path.isfile(sig_idx_path):\n",
    "                signature = np.load(sig_path, allow_pickle=True)\n",
    "                self.sig_idx = np.load(\n",
    "                    sig_idx_path, \n",
    "                    allow_pickle=True\n",
    "                ).item()\n",
    "                print(f\"Loaded signature from row {self.sig_idx}\")\n",
    "        else:\n",
    "            signature = np.full(\n",
    "                (len(hash_functions), len(docs_dict)), \n",
    "                fill_value=np.inf\n",
    "            )\n",
    "            self.sig_idx = -1\n",
    "\n",
    "        for r in tqdm(\n",
    "            range(0, num_rows),\n",
    "            total=num_rows,\n",
    "            desc='[Signature matrix] row number',\n",
    "            leave=False\n",
    "        ):\n",
    "            if r < self.sig_idx:\n",
    "                continue\n",
    "\n",
    "            hash_values = [\n",
    "                f(r)\n",
    "                for f in hash_functions\n",
    "            ]\n",
    "            for c, shingles in enumerate(docs_dict.values()):\n",
    "                if r in shingles:\n",
    "                    for i, hash_val in enumerate(hash_values):\n",
    "                        if hash_val < signature[i,c]:\n",
    "                            signature[i,c] = hash_val\n",
    "\n",
    "            self.sig_idx = r\n",
    "            if (self.sig_idx % checkpoint_freq == 0) and \\\n",
    "                self.checkpoint_path is not None:\n",
    "                np.save(sig_path, signature)\n",
    "                np.save(sig_idx_path, self.sig_idx)\n",
    "\n",
    "        if self.checkpoint_path is not None:\n",
    "            np.save(sig_path, signature)\n",
    "            np.save(sig_idx_path, self.sig_idx)\n",
    "        \n",
    "        return signature.astype(np.uint32)\n",
    "\n",
    "    def _find_lsh_params(self, t: int, n: int) -> tuple[int]:\n",
    "        \"\"\"Note that a lower b means that two items must match \n",
    "        a higher number of rows. By taking the floor of b, we \n",
    "        favor more similar pairs.\n",
    "        \"\"\"\n",
    "        def equations(vars):\n",
    "            b, r = vars\n",
    "            eq1 = t - (1 / b) ** (1 / r)\n",
    "            eq2 = n - b * r\n",
    "            return [eq1, eq2]\n",
    "\n",
    "        b, r =  fsolve(equations, (1, 1))\n",
    "        b = np.floor(b)\n",
    "        r = n // b\n",
    "        return int(b), int(r)\n",
    "\n",
    "    def _lsh(\n",
    "        self, \n",
    "        signature: np.ndarray, \n",
    "        b: int\n",
    "    ) -> set[tuple[int, int]]:\n",
    "        candidate_pairs = set()\n",
    "        \n",
    "        for band in np.array_split(signature, b):\n",
    "            \n",
    "            # column tuple -> list of column indices having that tuple\n",
    "            same_columns = defaultdict(list) \n",
    "            \n",
    "            for c in range(band.shape[1]):\n",
    "                column = band[:,c]\n",
    "                same_columns[tuple(column)].append(c)\n",
    "\n",
    "            filtered_same_columns = dict()\n",
    "            for k, values in same_columns.items():\n",
    "                if len(values) >= 2:\n",
    "                    filtered_same_columns[k] = values\n",
    "\n",
    "            for values in filtered_same_columns.values():\n",
    "                for pair in combinations(values, 2):\n",
    "                    candidate_pairs.add(pair)\n",
    "\n",
    "        return candidate_pairs\n",
    "\n",
    "    def _check_threshold_on_signature(\n",
    "        self, \n",
    "        candidate_pairs: list[tuple[int, int]], \n",
    "        signature: np.ndarray, \n",
    "        t: float\n",
    "    ) -> tuple[set[tuple[tuple[int, int], float]]]:\n",
    "        similar_pairs = set()\n",
    "        false_positive_pairs = set()\n",
    "\n",
    "        for (x, y) in candidate_pairs:\n",
    "            x_col = signature[:,x]\n",
    "            y_col = signature[:,y]\n",
    "            similarity = sum(x_col == y_col) / signature.shape[0]\n",
    "            tup = ((x, y), similarity)\n",
    "            if similarity >= t:\n",
    "                similar_pairs.add(tup)\n",
    "            else:\n",
    "                false_positive_pairs.add(tup)\n",
    "\n",
    "        return similar_pairs, false_positive_pairs\n",
    "\n",
    "    def check_threshold_on_cm(\n",
    "        self\n",
    "    ) -> tuple[set[tuple[tuple[int, int], float]]]:\n",
    "        \"\"\"Returns two sets of pairs. The first is the set\n",
    "        of similar pairs obtained after checking the candidate\n",
    "        pairs returned by the LSH procedure (before the double-check\n",
    "        on the signature matrix) against the actual Jaccard\n",
    "        similarity computed from the characteristic matrix.\n",
    "\n",
    "        The second is the set of false positive pairs identified\n",
    "        after the double-check against the characteristic matrix.\n",
    "        \"\"\"\n",
    "        similar_pairs = set()\n",
    "        false_positive_pairs = set()\n",
    "\n",
    "        for (x, y) in self.candidate_pairs:\n",
    "            similarity = jaccard_similarity(\n",
    "                self.docs_dict[x], \n",
    "                self.docs_dict[y]\n",
    "            )\n",
    "            tup = ((x, y), similarity)\n",
    "            if similarity >= self.threshold:\n",
    "                similar_pairs.add(tup)\n",
    "            else:\n",
    "                false_positive_pairs.add(tup)\n",
    "\n",
    "        return similar_pairs, false_positive_pairs\n",
    "\n",
    "    def get_shingle_set(self) -> set[int]:\n",
    "        return self.shingle_set\n",
    "\n",
    "    def get_char_set(self) -> set[str]:\n",
    "        return self.char_set\n",
    "\n",
    "    def get_docs_dict(self) -> dict[int, np.ndarray]:\n",
    "        return self.docs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(\n",
    "    x: list, \n",
    "    y: list\n",
    ") -> float:\n",
    "    return sum(\n",
    "        [np.abs(val2 - val1) for val1, val2 in zip(x, y)]\n",
    "    ) / len(x)\n",
    "\n",
    "def evaluate_on_cm(\n",
    "    sig_dict: dict[tuple[int, int], float], \n",
    "    cm_dict: dict[tuple[int, int], float]\n",
    ") -> tuple[int, float]:\n",
    "    \"\"\"Evaluates the model performance by computing\n",
    "    the number of false positive pairs and the\n",
    "    mean absolute error (MAE) against the characteristic\n",
    "    matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sig_dict : dict[tuple[int, int], float]\n",
    "        Dictionary that maps each similar pair to the\n",
    "        corresponding similarity value obtained as\n",
    "        estimation from the signature matrix.\n",
    "\n",
    "    cm_dict : dict[tuple[int, int], float]\n",
    "        Dictionary that maps each similar pair to the\n",
    "        corresponding similarity value obtained by\n",
    "        computing the Jaccard similarity on the \n",
    "        characteristic matrix.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The number of false positive pairs and the MAE.\n",
    "    \"\"\"\n",
    "    common = set(sig_dict).intersection(set(cm_dict))\n",
    "    num_wrong = len(sig_dict) - len(common)\n",
    "\n",
    "    sig_values = []\n",
    "    cm_values = []\n",
    "\n",
    "    for pair in common:\n",
    "        sig_values.append(sig_dict[pair])\n",
    "        cm_values.append(cm_dict[pair])\n",
    "\n",
    "    return num_wrong, \\\n",
    "        mean_absolute_error(sig_values, cm_values) \n",
    "\n",
    "def train_model(\n",
    "    model: LSHModel, \n",
    "    data_path: str, \n",
    "    num_docs: int,\n",
    "    verbose: bool = False,\n",
    "    filtering_pipeline: Optional[list[Callable[[str], str]]] = None, \n",
    "    preprocessing_pipeline: Optional[list[Callable[[str], str]]] = None  \n",
    ") -> LSHModel:\n",
    "    \"\"\"Trains the model on a given number of documents\n",
    "    taken from a provided dataset. Training here means\n",
    "    adding the shingles of the documents to the model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : LSHModel\n",
    "        The model to be trained.\n",
    "\n",
    "    data_path : str\n",
    "        The path where the files of the dataset are\n",
    "        stored.\n",
    "\n",
    "    num_docs : int\n",
    "        The number of documents on which the model\n",
    "        will be trained.\n",
    "\n",
    "    verbose : bool\n",
    "        Flag that determines whether to print \n",
    "        information about the processing.\n",
    "\n",
    "    filtering_pipeline : Optional[list[Callable[[str], str]]]\n",
    "        List of functions that take a string and return a string.\n",
    "        This is used on the text field of the dataframe, before\n",
    "        feeding the data to the model.\n",
    "\n",
    "    preprocessing_pipeline : Optional[list[Callable[[str], str]]]\n",
    "        List of functions that take a string and return a string.\n",
    "        This is used to preprocess documents being added to \n",
    "        the model.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The trained model.\n",
    "    \"\"\"\n",
    "    files = []\n",
    "\n",
    "    for name in os.listdir(data_path):\n",
    "        full_path = os.path.join(data_path, name)\n",
    "        if os.path.isfile(full_path):\n",
    "            files.append(full_path)\n",
    "\n",
    "    duplicates = 0\n",
    "    count = num_docs\n",
    "\n",
    "    with tqdm(\n",
    "        total=num_docs,\n",
    "        desc='Adding documents to model',\n",
    "        leave=False\n",
    "    ) as pbar:\n",
    "        for file in files:\n",
    "            if count == 0:\n",
    "                break\n",
    "\n",
    "            if verbose:\n",
    "                print(f'Reading file {file}')\n",
    "            df = pd.read_csv(\n",
    "                file, \n",
    "                compression='gzip', \n",
    "                index_col=0,\n",
    "                encoding='utf-8', \n",
    "                quoting=csv.QUOTE_ALL,\n",
    "                low_memory=False\n",
    "            )\n",
    "\n",
    "            df = df[df['language'] == 'en']\n",
    "\n",
    "            if filtering_pipeline is not None:\n",
    "                for filter_f in filtering_pipeline:\n",
    "                    df['text'] = df['text'].apply(filter_f)\n",
    "\n",
    "            df_unique = df.drop_duplicates(subset=['text'])\n",
    "            duplicates += len(df) - len(df_unique)\n",
    "\n",
    "            for index, row in tqdm(\n",
    "                df_unique.iterrows(),\n",
    "                total=len(df_unique),\n",
    "                desc='Reading file',\n",
    "                leave=False\n",
    "            ):\n",
    "                text = row['text']\n",
    "                model.add_document(\n",
    "                    text,\n",
    "                    preprocessing_pipeline\n",
    "                )\n",
    "                \n",
    "                count -= 1\n",
    "                pbar.update(1)\n",
    "                if count == 0:\n",
    "                    break\n",
    "\n",
    "    if verbose:       \n",
    "        print(f'Found {duplicates} duplicates in files')\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_text(\n",
    "    idx_ls: list[int], \n",
    "    data_path: str\n",
    ") -> list[tuple[int, str]]:\n",
    "    \"\"\"Returns a list containing the original texts\n",
    "    from the dataset (before the preprocessing) alongside\n",
    "    their indices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    idx_ls : list[int]\n",
    "        The list of the indices of the documents to \n",
    "        be retrieved.\n",
    "\n",
    "    data_path : str\n",
    "        The path where the files of the dataset are\n",
    "        stored.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuples containing the indices of the documents and their\n",
    "    original text.\n",
    "    \"\"\"\n",
    "    max_idx = max(idx_ls)\n",
    "    result = []\n",
    "    \n",
    "    files = []\n",
    "\n",
    "    for name in os.listdir(data_path):\n",
    "        full_path = os.path.join(data_path, name)\n",
    "        if os.path.isfile(full_path):\n",
    "            files.append(full_path)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for file in files:\n",
    "        df = pd.read_csv(\n",
    "            file, \n",
    "            compression='gzip', \n",
    "            index_col=0,\n",
    "            encoding='utf-8', \n",
    "            quoting=csv.QUOTE_ALL,\n",
    "            low_memory=False\n",
    "        )\n",
    "\n",
    "        df = df[df['language'] == 'en']\n",
    "        df_unique = df.drop_duplicates(subset=['text'])\n",
    "\n",
    "        for index, row in df_unique.iterrows():\n",
    "            if count in idx_ls:\n",
    "                result.append((count, row['text']))\n",
    "            if count == max_idx:\n",
    "                return result\n",
    "            count += 1\n",
    "\n",
    "def mean_pooling(\n",
    "    model_output: torch.Tensor, \n",
    "    attn_mask: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Returns the mean of the embeddings taken from \n",
    "    the last layer of the model, in order to give \n",
    "    a single embedding for each document. The mean\n",
    "    is weighted with the attention mask, so that \n",
    "    the padding and control tokens added by the model\n",
    "    are not considered in the mean.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_output : torch.Tensor\n",
    "        Embeddings for all the documents.\n",
    "\n",
    "    attn_mask : torch.Tensor\n",
    "        The attention mask of the model for all the\n",
    "        documents.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The weighted mean embedding for each document. \n",
    "    \"\"\"\n",
    "    token_embeddings = model_output['last_hidden_state']\n",
    "\n",
    "    # attn_mask shape: [13, 512] -> [13, 512, 768]\n",
    "    expanded_attn_mask = attn_mask.unsqueeze(-1).expand_as(token_embeddings)\n",
    "\n",
    "    # * or torch.mul: out_i = input_i x other_i \n",
    "    # might use torch.clamp to avoid dividing by 0\n",
    "    return torch.sum(\n",
    "        token_embeddings * expanded_attn_mask, 1\n",
    "    ) / expanded_attn_mask.sum(1)\n",
    "\n",
    "def torch_cosine_similarity(x, y):\n",
    "    return torch.matmul(\n",
    "        F.normalize(x, dim=-1), \n",
    "        F.normalize(y, dim=-1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(r'e:\\datasets\\ukraine'):\n",
    "    DATA_PATH = r'e:\\datasets\\ukraine'\n",
    "else:\n",
    "    DATA_PATH = os.path.join(os.getcwd(), 'dataset')\n",
    "\n",
    "os.makedirs('img', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering_pipeline = [\n",
    "    remove_https\n",
    "]\n",
    "\n",
    "preprocessing_pipeline = [\n",
    "    strip_accents,\n",
    "    replace_chars,\n",
    "    get_lemmatizer(\n",
    "        nlp,\n",
    "        allow_numbers=True\n",
    "    ),\n",
    "    str.lower,\n",
    "    strip_punctuation,\n",
    "    remove_non_ascii,\n",
    "    normalize_white_space\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shingle and character number growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 k, 10 docs]:\n",
      "\t42 characters\n",
      "\t1140 shingles\n",
      "\t141.1 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 k, 100 docs]:\n",
      "\t48 characters\n",
      "\t6045 shingles\n",
      "\t118.54 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 k, 1000 docs]:\n",
      "\t57 characters\n",
      "\t20999 shingles\n",
      "\t111.25 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 k, 10000 docs]:\n",
      "\t64 characters\n",
      "\t61010 shingles\n",
      "\t110.4606 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 k, 20000 docs]:\n",
      "\t66 characters\n",
      "\t82944 shingles\n",
      "\t109.8403 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 k, 30000 docs]:\n",
      "\t66 characters\n",
      "\t100039 shingles\n",
      "\t110.1393 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 k, 50000 docs]:\n",
      "\t67 characters\n",
      "\t124993 shingles\n",
      "\t110.62218 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 k, 70000 docs]:\n",
      "\t68 characters\n",
      "\t140857 shingles\n",
      "\t110.2275 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 k, 100000 docs]:\n",
      "\t68 characters\n",
      "\t159273 shingles\n",
      "\t110.2074 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 k, 150000 docs]:\n",
      "\t68 characters\n",
      "\t178459 shingles\n",
      "\t109.99552 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 k, 200000 docs]:\n",
      "\t68 characters\n",
      "\t193961 shingles\n",
      "\t109.614735 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 k, 10 docs]:\n",
      "\t42 characters\n",
      "\t1258 shingles\n",
      "\t143.7 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 k, 100 docs]:\n",
      "\t48 characters\n",
      "\t7988 shingles\n",
      "\t120.87 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 k, 1000 docs]:\n",
      "\t57 characters\n",
      "\t39135 shingles\n",
      "\t113.256 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 k, 10000 docs]:\n",
      "\t64 characters\n",
      "\t148284 shingles\n",
      "\t112.602 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 k, 20000 docs]:\n",
      "\t66 characters\n",
      "\t216257 shingles\n",
      "\t111.9935 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 k, 30000 docs]:\n",
      "\t66 characters\n",
      "\t271574 shingles\n",
      "\t112.32153333333333 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 k, 50000 docs]:\n",
      "\t67 characters\n",
      "\t360026 shingles\n",
      "\t112.84776 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 k, 70000 docs]:\n",
      "\t68 characters\n",
      "\t421536 shingles\n",
      "\t112.44824285714286 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 k, 100000 docs]:\n",
      "\t68 characters\n",
      "\t496146 shingles\n",
      "\t112.4488 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 k, 150000 docs]:\n",
      "\t68 characters\n",
      "\t577999 shingles\n",
      "\t112.22375333333333 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 k, 200000 docs]:\n",
      "\t68 characters\n",
      "\t648281 shingles\n",
      "\t111.80891 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 k, 10 docs]:\n",
      "\t42 characters\n",
      "\t1316 shingles\n",
      "\t145.9 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 k, 100 docs]:\n",
      "\t48 characters\n",
      "\t9064 shingles\n",
      "\t122.23 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 k, 1000 docs]:\n",
      "\t57 characters\n",
      "\t54946 shingles\n",
      "\t114.433 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 k, 10000 docs]:\n",
      "\t64 characters\n",
      "\t261747 shingles\n",
      "\t113.9606 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 k, 20000 docs]:\n",
      "\t66 characters\n",
      "\t402986 shingles\n",
      "\t113.36055 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 k, 30000 docs]:\n",
      "\t66 characters\n",
      "\t519514 shingles\n",
      "\t113.70433333333334 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 k, 50000 docs]:\n",
      "\t67 characters\n",
      "\t711702 shingles\n",
      "\t114.25588 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 k, 70000 docs]:\n",
      "\t68 characters\n",
      "\t851091 shingles\n",
      "\t113.85078571428572 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 k, 100000 docs]:\n",
      "\t68 characters\n",
      "\t1026157 shingles\n",
      "\t113.87512 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 k, 150000 docs]:\n",
      "\t68 characters\n",
      "\t1228670 shingles\n",
      "\t113.65327333333333 avg shingles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 k, 200000 docs]:\n",
      "\t68 characters\n",
      "\t1407594 shingles\n",
      "\t113.2201 avg shingles\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = dict()\n",
    "\n",
    "for k in [4, 5, 6]:\n",
    "    results[k] = {\n",
    "        'docs': [],\n",
    "        'characters': [],\n",
    "        'shingles': [],\n",
    "        'avg_shingles': []\n",
    "    }\n",
    "\n",
    "    for num_docs in [\n",
    "        10, 100, 1000, 10000, \n",
    "        20000, 30000, 50000,\n",
    "        70000, 100000, 150000,\n",
    "        200000\n",
    "    ]:\n",
    "        ckpt_path = f'checkpoints/k{k}_d{num_docs}'\n",
    "        model = LSHModel(\n",
    "            k=k,\n",
    "            threshold=0.1,\n",
    "            num_hashes=100,\n",
    "            shingle_hash_bits=16,\n",
    "            track_shingles=True,\n",
    "            checkpoint_path=ckpt_path\n",
    "        )\n",
    "\n",
    "        if os.path.isdir(ckpt_path) and \\\n",
    "            len(os.listdir(ckpt_path)) > 0:\n",
    "            model.load_checkpoint()\n",
    "        else:\n",
    "            model = train_model(\n",
    "                model=model, \n",
    "                data_path=DATA_PATH,\n",
    "                num_docs=num_docs,\n",
    "                verbose=False,\n",
    "                filtering_pipeline=filtering_pipeline,\n",
    "                preprocessing_pipeline=preprocessing_pipeline,\n",
    "            )\n",
    "            model.save_checkpoint()\n",
    "\n",
    "        results[k]['docs'].append(num_docs)\n",
    "        results[k]['characters'].append(len(model.get_char_set()))\n",
    "        results[k]['shingles'].append(len(model.get_shingle_set()))\n",
    "\n",
    "        docs_dict = model.get_docs_dict()\n",
    "        avg_shingles = np.mean(\n",
    "            [\n",
    "                len(doc_shingles) \n",
    "                for doc_shingles in docs_dict.values()\n",
    "            ]\n",
    "        )\n",
    "        results[k]['avg_shingles'].append(avg_shingles)\n",
    "\n",
    "        print(\n",
    "            f'[{k} k, {num_docs} docs]:\\n'\n",
    "            f'\\t{len(model.get_char_set())} characters\\n'\n",
    "            f'\\t{len(model.get_shingle_set())} shingles\\n'\n",
    "            f'\\t{avg_shingles} avg shingles\\n'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k in [4, 5, 6]:\n",
    "    plt.plot(\n",
    "        results[k]['docs'], \n",
    "        results[k]['shingles'],\n",
    "        label=f'k = {k}'\n",
    "    )\n",
    "plt.xticks([0, 50000, 100000, 150000, 200000])\n",
    "plt.xlabel('Number of documents')\n",
    "plt.ylabel('Number of shingles')\n",
    "plt.title('Shingles growth')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('img/shingles_growth.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(\n",
    "    results[5]['docs'], \n",
    "    results[5]['characters']\n",
    ")\n",
    "plt.xticks([0, 50000, 100000, 150000, 200000])\n",
    "plt.xlabel('Number of documents')\n",
    "plt.ylabel('Number of characters')\n",
    "plt.title('Characters growth')\n",
    "plt.savefig('img/char_growth.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of hash bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[k 3, 12 bits]:\n",
      "\t10.873566500005836 seconds\n",
      "\t828 wrong out of 1988 (0.5835010060362174 Prec.) (0.1 t)\n",
      "\t0.027296709304486726 MAE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[k 3, 14 bits]:\n",
      "\t14.825079400005052 seconds\n",
      "\t344 wrong out of 1047 (0.6714422158548233 Prec.) (0.1 t)\n",
      "\t0.019095968405134466 MAE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[k 3, 16 bits]:\n",
      "\t32.19386189999932 seconds\n",
      "\t555 wrong out of 1358 (0.5913107511045655 Prec.) (0.1 t)\n",
      "\t0.02161256677766821 MAE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[k 3, 18 bits]:\n",
      "\t109.58982149999792 seconds\n",
      "\t389 wrong out of 1059 (0.6326723323890463 Prec.) (0.1 t)\n",
      "\t0.019830625756691485 MAE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[k 3, 19 bits]:\n",
      "\t199.52453850000165 seconds\n",
      "\t861 wrong out of 1650 (0.4781818181818182 Prec.) (0.1 t)\n",
      "\t0.03115090980550743 MAE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[k 3, 20 bits]:\n",
      "\t394.60135539999465 seconds\n",
      "\t547 wrong out of 1235 (0.557085020242915 Prec.) (0.1 t)\n",
      "\t0.021456358052244377 MAE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[k 3, 22 bits]:\n",
      "\t1552.1595470999964 seconds\n",
      "\t653 wrong out of 1346 (0.5148588410104011 Prec.) (0.1 t)\n",
      "\t0.025835155729074844 MAE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[k 4, 12 bits]:\n",
      "\t13.415311700002349 seconds\n",
      "\t317 wrong out of 491 (0.3543788187372709 Prec.) (0.1 t)\n",
      "\t0.02336637226431859 MAE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[k 4, 14 bits]:\n",
      "\t15.635955099998682 seconds\n",
      "\t210 wrong out of 326 (0.3558282208588957 Prec.) (0.1 t)\n",
      "\t0.02212482070200454 MAE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[k 4, 16 bits]:\n",
      "\t33.96939469999779 seconds\n",
      "\t183 wrong out of 287 (0.3623693379790941 Prec.) (0.1 t)\n",
      "\t0.02317018446897908 MAE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[k 4, 18 bits]:\n",
      "\t105.85842709999997 seconds\n",
      "\t152 wrong out of 258 (0.4108527131782946 Prec.) (0.1 t)\n",
      "\t0.028766453888946233 MAE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[k 4, 19 bits]:\n",
      "\t197.83542330000637 seconds\n",
      "\t64 wrong out of 146 (0.5616438356164384 Prec.) (0.1 t)\n",
      "\t0.017888358192926054 MAE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\projects\\amd\\similar_tweets.ipynb Cella 22\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=32'>33</a>\u001b[0m model \u001b[39m=\u001b[39m train_model(\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=33'>34</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel, \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=34'>35</a>\u001b[0m     data_path\u001b[39m=\u001b[39mDATA_PATH,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=38'>39</a>\u001b[0m     preprocessing_pipeline\u001b[39m=\u001b[39mpreprocessing_pipeline,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=39'>40</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=40'>41</a>\u001b[0m model\u001b[39m.\u001b[39msave_checkpoint()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=42'>43</a>\u001b[0m sig_tp \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(model\u001b[39m.\u001b[39;49mget_similar_pairs())\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=44'>45</a>\u001b[0m end_time \u001b[39m=\u001b[39m timeit\u001b[39m.\u001b[39mdefault_timer()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=45'>46</a>\u001b[0m time_delta \u001b[39m=\u001b[39m end_time \u001b[39m-\u001b[39m start_time\n",
      "\u001b[1;32me:\\projects\\amd\\similar_tweets.ipynb Cella 22\u001b[0m in \u001b[0;36mLSHModel.get_similar_pairs\u001b[1;34m(self, checkpoint_path, checkpoint_freq)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=134'>135</a>\u001b[0m hg \u001b[39m=\u001b[39m HashGenerator(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_shingles)\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=135'>136</a>\u001b[0m hash_functions \u001b[39m=\u001b[39m [\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=136'>137</a>\u001b[0m     hg\u001b[39m.\u001b[39mnext()\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=137'>138</a>\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_hashes)\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=138'>139</a>\u001b[0m ]\n\u001b[1;32m--> <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=139'>140</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_signature(\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=140'>141</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdocs_dict,\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=141'>142</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_shingles,\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=142'>143</a>\u001b[0m     hash_functions,\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=143'>144</a>\u001b[0m     checkpoint_path,\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=144'>145</a>\u001b[0m     checkpoint_freq\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=145'>146</a>\u001b[0m )\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=146'>147</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_find_lsh_params(\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=147'>148</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mthreshold,\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=148'>149</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_hashes\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=149'>150</a>\u001b[0m )\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=150'>151</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcandidate_pairs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lsh(\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=151'>152</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature,\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=152'>153</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=153'>154</a>\u001b[0m )\n",
      "\u001b[1;32me:\\projects\\amd\\similar_tweets.ipynb Cella 22\u001b[0m in \u001b[0;36mLSHModel._build_signature\u001b[1;34m(self, docs_dict, num_rows, hash_functions, checkpoint_path, checkpoint_freq)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=208'>209</a>\u001b[0m     signature \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfull(\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=209'>210</a>\u001b[0m         (\u001b[39mlen\u001b[39m(hash_functions), \u001b[39mlen\u001b[39m(docs_dict)), \n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=210'>211</a>\u001b[0m         fill_value\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39minf\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=211'>212</a>\u001b[0m     )\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=212'>213</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msig_idx \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=214'>215</a>\u001b[0m \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m tqdm(\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=215'>216</a>\u001b[0m     \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, num_rows),\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=216'>217</a>\u001b[0m     total\u001b[39m=\u001b[39mnum_rows,\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=217'>218</a>\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[Signature matrix] row number\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=218'>219</a>\u001b[0m     leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=219'>220</a>\u001b[0m ):\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=220'>221</a>\u001b[0m     \u001b[39mif\u001b[39;00m r \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msig_idx:\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000063?line=221'>222</a>\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Users\\gabri\\anaconda3\\envs\\tf_p3.9\\lib\\site-packages\\tqdm\\std.py:1190\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1188\u001b[0m dt \u001b[39m=\u001b[39m cur_t \u001b[39m-\u001b[39m last_print_t\n\u001b[0;32m   1189\u001b[0m \u001b[39mif\u001b[39;00m dt \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m mininterval \u001b[39mand\u001b[39;00m cur_t \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m min_start_t:\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(n \u001b[39m-\u001b[39;49m last_print_n)\n\u001b[0;32m   1191\u001b[0m     last_print_n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_print_n\n\u001b[0;32m   1192\u001b[0m     last_print_t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_print_t\n",
      "File \u001b[1;32md:\\Users\\gabri\\anaconda3\\envs\\tf_p3.9\\lib\\site-packages\\tqdm\\std.py:1241\u001b[0m, in \u001b[0;36mtqdm.update\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1239\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ema_dn(dn)\n\u001b[0;32m   1240\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ema_dt(dt)\n\u001b[1;32m-> 1241\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrefresh(lock_args\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlock_args)\n\u001b[0;32m   1242\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdynamic_miniters:\n\u001b[0;32m   1243\u001b[0m     \u001b[39m# If no `miniters` was specified, adjust automatically to the\u001b[39;00m\n\u001b[0;32m   1244\u001b[0m     \u001b[39m# maximum iteration rate seen so far between two prints.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m     \u001b[39m# e.g.: After running `tqdm.update(5)`, subsequent\u001b[39;00m\n\u001b[0;32m   1246\u001b[0m     \u001b[39m# calls to `tqdm.update()` will only cause an update after\u001b[39;00m\n\u001b[0;32m   1247\u001b[0m     \u001b[39m# at least 5 more iterations.\u001b[39;00m\n\u001b[0;32m   1248\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxinterval \u001b[39mand\u001b[39;00m dt \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxinterval:\n",
      "File \u001b[1;32md:\\Users\\gabri\\anaconda3\\envs\\tf_p3.9\\lib\\site-packages\\tqdm\\std.py:1346\u001b[0m, in \u001b[0;36mtqdm.refresh\u001b[1;34m(self, nolock, lock_args)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1345\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39macquire()\n\u001b[1;32m-> 1346\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdisplay()\n\u001b[0;32m   1347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nolock:\n\u001b[0;32m   1348\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32md:\\Users\\gabri\\anaconda3\\envs\\tf_p3.9\\lib\\site-packages\\tqdm\\std.py:1494\u001b[0m, in \u001b[0;36mtqdm.display\u001b[1;34m(self, msg, pos)\u001b[0m\n\u001b[0;32m   1492\u001b[0m \u001b[39mif\u001b[39;00m pos:\n\u001b[0;32m   1493\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmoveto(pos)\n\u001b[1;32m-> 1494\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msp(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__str__\u001b[39;49m() \u001b[39mif\u001b[39;49;00m msg \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m msg)\n\u001b[0;32m   1495\u001b[0m \u001b[39mif\u001b[39;00m pos:\n\u001b[0;32m   1496\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmoveto(\u001b[39m-\u001b[39mpos)\n",
      "File \u001b[1;32md:\\Users\\gabri\\anaconda3\\envs\\tf_p3.9\\lib\\site-packages\\tqdm\\std.py:350\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.print_status\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprint_status\u001b[39m(s):\n\u001b[0;32m    349\u001b[0m     len_s \u001b[39m=\u001b[39m disp_len(s)\n\u001b[1;32m--> 350\u001b[0m     fp_write(\u001b[39m'\u001b[39;49m\u001b[39m\\r\u001b[39;49;00m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m s \u001b[39m+\u001b[39;49m (\u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39mmax\u001b[39;49m(last_len[\u001b[39m0\u001b[39;49m] \u001b[39m-\u001b[39;49m len_s, \u001b[39m0\u001b[39;49m)))\n\u001b[0;32m    351\u001b[0m     last_len[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m len_s\n",
      "File \u001b[1;32md:\\Users\\gabri\\anaconda3\\envs\\tf_p3.9\\lib\\site-packages\\tqdm\\std.py:343\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.fp_write\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfp_write\u001b[39m(s):\n\u001b[1;32m--> 343\u001b[0m     fp\u001b[39m.\u001b[39;49mwrite(_unicode(s))\n\u001b[0;32m    344\u001b[0m     fp_flush()\n",
      "File \u001b[1;32md:\\Users\\gabri\\anaconda3\\envs\\tf_p3.9\\lib\\site-packages\\tqdm\\utils.py:145\u001b[0m, in \u001b[0;36mDisableOnWriteError.disable_on_exception.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    146\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    147\u001b[0m         \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39merrno \u001b[39m!=\u001b[39m \u001b[39m5\u001b[39m:\n",
      "File \u001b[1;32md:\\Users\\gabri\\anaconda3\\envs\\tf_p3.9\\lib\\site-packages\\ipykernel\\iostream.py:529\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    527\u001b[0m is_child \u001b[39m=\u001b[39m (\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_master_process())\n\u001b[0;32m    528\u001b[0m \u001b[39m# only touch the buffer in the IO thread to avoid races\u001b[39;00m\n\u001b[1;32m--> 529\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpub_thread\u001b[39m.\u001b[39;49mschedule(\u001b[39mlambda\u001b[39;49;00m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer\u001b[39m.\u001b[39;49mwrite(string))\n\u001b[0;32m    530\u001b[0m \u001b[39mif\u001b[39;00m is_child:\n\u001b[0;32m    531\u001b[0m     \u001b[39m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[39;00m\n\u001b[0;32m    532\u001b[0m     \u001b[39m# and this helps.\u001b[39;00m\n\u001b[0;32m    533\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_subprocess_flush_pending:\n",
      "File \u001b[1;32md:\\Users\\gabri\\anaconda3\\envs\\tf_p3.9\\lib\\site-packages\\ipykernel\\iostream.py:214\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_events\u001b[39m.\u001b[39mappend(f)\n\u001b[0;32m    213\u001b[0m     \u001b[39m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event_pipe\u001b[39m.\u001b[39;49msend(\u001b[39mb\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    215\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     f()\n",
      "File \u001b[1;32md:\\Users\\gabri\\anaconda3\\envs\\tf_p3.9\\lib\\site-packages\\zmq\\sugar\\socket.py:547\u001b[0m, in \u001b[0;36mSocket.send\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    540\u001b[0m         data \u001b[39m=\u001b[39m zmq\u001b[39m.\u001b[39mFrame(\n\u001b[0;32m    541\u001b[0m             data,\n\u001b[0;32m    542\u001b[0m             track\u001b[39m=\u001b[39mtrack,\n\u001b[0;32m    543\u001b[0m             copy\u001b[39m=\u001b[39mcopy \u001b[39mor\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    544\u001b[0m             copy_threshold\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy_threshold,\n\u001b[0;32m    545\u001b[0m         )\n\u001b[0;32m    546\u001b[0m     data\u001b[39m.\u001b[39mgroup \u001b[39m=\u001b[39m group\n\u001b[1;32m--> 547\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Socket, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49msend(data, flags\u001b[39m=\u001b[39;49mflags, copy\u001b[39m=\u001b[39;49mcopy, track\u001b[39m=\u001b[39;49mtrack)\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:718\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:765\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:242\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\Users\\gabri\\anaconda3\\envs\\tf_p3.9\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = dict()\n",
    "\n",
    "for k in [3, 4, 5]:\n",
    "    ls = []\n",
    "\n",
    "    for n_bits in [12, 14, 16, 18, 19, 20, 22]:\n",
    "        ckpt_path = f'checkpoints/k{k}_n_bits{n_bits}'\n",
    "        time_path = f'{ckpt_path}/time.npy'\n",
    "\n",
    "        model = LSHModel(\n",
    "            k=k,\n",
    "            threshold=0.1,\n",
    "            num_hashes=100,\n",
    "            shingle_hash_bits=n_bits,\n",
    "            track_shingles=True,\n",
    "            checkpoint_path=ckpt_path\n",
    "        )\n",
    "\n",
    "        if os.path.isdir(ckpt_path) and \\\n",
    "            len(os.listdir(ckpt_path)) > 0:\n",
    "            model.load_checkpoint()\n",
    "\n",
    "            time_delta = np.load(\n",
    "                f'{ckpt_path}/time.npy', \n",
    "                allow_pickle=True\n",
    "            )\n",
    "\n",
    "            sig_tp = dict(model.get_similar_pairs())\n",
    "            \n",
    "        else:\n",
    "            start_time = timeit.default_timer()\n",
    "\n",
    "            model = train_model(\n",
    "                model=model, \n",
    "                data_path=DATA_PATH,\n",
    "                num_docs=100,\n",
    "                verbose=False,\n",
    "                filtering_pipeline=filtering_pipeline,\n",
    "                preprocessing_pipeline=preprocessing_pipeline,\n",
    "            )\n",
    "            model.save_checkpoint()\n",
    "\n",
    "            sig_tp = dict(model.get_similar_pairs())\n",
    "\n",
    "            end_time = timeit.default_timer()\n",
    "            time_delta = end_time - start_time\n",
    "            np.save(f'{ckpt_path}/time.npy', time_delta)\n",
    "\n",
    "        cm_tp, _ = model.check_threshold_on_cm()\n",
    "        cm_tp = dict(cm_tp)\n",
    "        num_wrong, mae = evaluate_on_cm(sig_tp, cm_tp)\n",
    "        correct = len(sig_tp) - num_wrong\n",
    "        ratio = correct / len(sig_tp)\n",
    "\n",
    "        ls.append(\n",
    "            (\n",
    "                n_bits, \n",
    "                time_delta,\n",
    "                len(sig_tp),\n",
    "                correct, \n",
    "                num_wrong,\n",
    "                ratio,\n",
    "                mae\n",
    "            )\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f'[k {k}, {n_bits} bits]:\\n'\n",
    "            f'\\t{time_delta} seconds\\n'\n",
    "            f'\\t{num_wrong} wrong out of {len(sig_tp)} ({ratio} Prec.) (0.1 t)\\n'\n",
    "            f'\\t{mae} MAE\\n'\n",
    "        )\n",
    "    \n",
    "    results[k] = pd.DataFrame(\n",
    "        ls,\n",
    "        columns=[\n",
    "            'Hash bits', \n",
    "            'Time delta (s)', \n",
    "            'Predicted pairs',\n",
    "            'Correct pairs (TP)', \n",
    "            'Wrong pairs (FP)', \n",
    "            'Correct ratio (Prec.)',\n",
    "            'MAE'\n",
    "        ]\n",
    "    ).set_index('Hash bits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Time delta (s)  Predicted pairs  Wrong pairs  Wrong ratio    MAE\n",
      "Hash bits                                                                  \n",
      "16                 31.111              334          210        0.629  0.018\n",
      "18                100.373              177           69        0.390  0.015\n",
      "19                194.698              435          310        0.713  0.028\n",
      "20                373.534              234          125        0.534  0.020\n",
      "22               1412.158              185           92        0.497  0.018\n",
      "           Time delta (s)  Predicted pairs  Wrong pairs  Wrong ratio    MAE\n",
      "Hash bits                                                                  \n",
      "16                 30.373               83           35        0.422  0.014\n",
      "18                 97.623              246          187        0.760  0.027\n",
      "19                184.124              110           60        0.545  0.014\n",
      "20                354.228              112           65        0.580  0.013\n",
      "22               1418.471               91           46        0.505  0.017\n"
     ]
    }
   ],
   "source": [
    "for k in [3, 4, 5]:\n",
    "    print(results[k].round(3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()\n",
    "\n",
    "for k in [3, 4, 5]:\n",
    "    ls = []\n",
    "\n",
    "    for t in [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.5]:\n",
    "        ckpt_path = f'checkpoints/k{k}_t{t}'\n",
    "\n",
    "        model = LSHModel(\n",
    "            k=k,\n",
    "            threshold=t,\n",
    "            num_hashes=100,\n",
    "            shingle_hash_bits=16,\n",
    "            track_shingles=True,\n",
    "            checkpoint_path=ckpt_path\n",
    "        )\n",
    "\n",
    "        if os.path.isdir(ckpt_path) and \\\n",
    "            len(os.listdir(ckpt_path)) > 0:\n",
    "            model.load_checkpoint()\n",
    "            sig_tp = dict(model.get_similar_pairs())\n",
    "            \n",
    "        else:\n",
    "            model = train_model(\n",
    "                model=model, \n",
    "                data_path=DATA_PATH,\n",
    "                num_docs=100,\n",
    "                verbose=False,\n",
    "                filtering_pipeline=filtering_pipeline,\n",
    "                preprocessing_pipeline=preprocessing_pipeline,\n",
    "            )\n",
    "            model.save_checkpoint()\n",
    "            sig_tp = dict(model.get_similar_pairs())\n",
    "\n",
    "        cm_tp, _ = model.check_threshold_on_cm()\n",
    "        cm_tp = dict(cm_tp)\n",
    "        num_wrong, mae = evaluate_on_cm(sig_tp, cm_tp)\n",
    "        correct = len(sig_tp) - num_wrong\n",
    "        ratio = correct / len(sig_tp)\n",
    "\n",
    "        ls.append(\n",
    "            (\n",
    "                t,\n",
    "                len(sig_tp),\n",
    "                correct, \n",
    "                num_wrong,\n",
    "                ratio,\n",
    "                mae\n",
    "            )\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f'[k {k}, {t} threshold]:\\n'\n",
    "            f'\\t{num_wrong} wrong out of {len(sig_tp)} \\\n",
    "                ({ratio} Prec.) (0.1 t)\\n'\n",
    "            f'\\t{mae} MAE\\n'\n",
    "        )\n",
    "    \n",
    "    results[k] = pd.DataFrame(\n",
    "        ls,\n",
    "        columns=[\n",
    "            'Threshold', \n",
    "            'Predicted pairs',\n",
    "            'Correct pairs (TP)', \n",
    "            'Wrong pairs (FP)', \n",
    "            'Correct ratio (Prec.)',\n",
    "            'MAE'\n",
    "        ]\n",
    "    ).set_index('Threshold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 500k Tweets comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LSH model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MORE THAN ONE MODEL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding documents to model:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file e:\\datasets\\ukraine\\0401_UkraineCombinedTweetsDeduped.csv.gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 191292 duplicates in files\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = f'checkpoints/test/test1'\n",
    "model = LSHModel(\n",
    "    k=5,\n",
    "    threshold=0.1,\n",
    "    num_hashes=100,\n",
    "    shingle_hash_bits=16,\n",
    "    track_shingles=True,\n",
    "    checkpoint_path=ckpt_path\n",
    ")\n",
    "model = train_model(\n",
    "    model=model, \n",
    "    data_path=DATA_PATH,\n",
    "    num_docs=100,\n",
    "    verbose=True,\n",
    "    filtering_pipeline=filtering_pipeline,\n",
    "    preprocessing_pipeline=preprocessing_pipeline,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding documents to model:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file e:\\datasets\\ukraine\\0401_UkraineCombinedTweetsDeduped.csv.gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 191292 duplicates in files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "ckpt_path = f'checkpoints/d100/k5_t0.1_bits16'\n",
    "model = LSHModel(\n",
    "    k=5,\n",
    "    threshold=0.1,\n",
    "    num_hashes=100,\n",
    "    shingle_hash_bits=16,\n",
    "    track_shingles=True,\n",
    "    checkpoint_path=ckpt_path\n",
    ")\n",
    "model = train_model(\n",
    "    model=model, \n",
    "    data_path=DATA_PATH,\n",
    "    num_docs=100,\n",
    "    verbose=True,\n",
    "    preprocessing_pipeline=preprocessing_pipeline,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded signature from row 65535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    }
   ],
   "source": [
    "similar_pairs = model.get_similar_pairs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPNet embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'sentence-transformers/all-mpnet-base-v2'\n",
    ")\n",
    "mpnet = AutoModel.from_pretrained(\n",
    "    'sentence-transformers/all-mpnet-base-v2'\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnet_preprocessing = [\n",
    "    replace_chars,\n",
    "    str.lower,\n",
    "    normalize_white_space\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  4,  6,  9, 10, 12, 13, 14, 15, 16, 19, 20, 21, 23, 25,\n",
       "       27, 28, 30, 31, 32, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50,\n",
       "       51, 52, 53, 57, 58, 63, 64, 66, 67, 69, 70, 71, 73, 75, 76, 77, 78,\n",
       "       79, 86, 87, 89, 91, 92, 96, 97, 98])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_ls = np.unique(\n",
    "    np.array(\n",
    "        [\n",
    "            list(pair)\n",
    "            for pair, _ in similar_pairs\n",
    "        ] \n",
    "    ).flatten()\n",
    ")\n",
    "text_dict = dict(get_text(idx_ls, DATA_PATH))\n",
    "\n",
    "preprocessed_texts = []\n",
    "for text in text_dict.values():\n",
    "    for f in mpnet_preprocessing:\n",
    "        text = f(text)\n",
    "    preprocessed_texts.append(text)\n",
    "\n",
    "encoded_input = tokenizer(\n",
    "    preprocessed_texts, \n",
    "    padding='max_length', \n",
    "    truncation=True, \n",
    "    return_tensors='pt'\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "embeddings_dict = {\n",
    "    key: val\n",
    "    for key, val in zip(text_dict.keys(), embeddings)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh_sims = []\n",
    "mpnet_sims = []\n",
    "\n",
    "for ((x_idx, y_idx), lsh_sim) in similar_pairs:\n",
    "    lsh_sims.append(lsh_sim)\n",
    "    mpnet_sims.append(\n",
    "        torch_cosine_similarity(\n",
    "            embeddings_dict[x_idx],\n",
    "            embeddings_dict[y_idx],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KendalltauResult(correlation=0.4790651278562069, pvalue=9.727797364038488e-09)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendalltau(lsh_sims, mpnet_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.6255073800230813, pvalue=1.1872875150277376e-09)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(lsh_sims, mpnet_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding documents to model:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file e:\\datasets\\ukraine\\0401_UkraineCombinedTweetsDeduped.csv.gzip\n",
      "Reading file e:\\datasets\\ukraine\\0402_UkraineCombinedTweetsDeduped.csv.gzip\n",
      "Reading file e:\\datasets\\ukraine\\0403_UkraineCombinedTweetsDeduped.csv.gzip\n",
      "Reading file e:\\datasets\\ukraine\\0404_UkraineCombinedTweetsDeduped.csv.gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\projects\\amd\\similar_tweets.ipynb Cella 46\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000126?line=30'>31</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000126?line=32'>33</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mReading file \u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000126?line=33'>34</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000126?line=34'>35</a>\u001b[0m     file, \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000126?line=35'>36</a>\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgzip\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000126?line=36'>37</a>\u001b[0m     index_col\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000126?line=37'>38</a>\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000126?line=38'>39</a>\u001b[0m     quoting\u001b[39m=\u001b[39;49mcsv\u001b[39m.\u001b[39;49mQUOTE_ALL,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000126?line=39'>40</a>\u001b[0m     low_memory\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000126?line=40'>41</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000126?line=42'>43</a>\u001b[0m df \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39mlanguage\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39men\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/amd/similar_tweets.ipynb#ch0000126?line=44'>45</a>\u001b[0m \u001b[39mfor\u001b[39;00m filter_f \u001b[39min\u001b[39;00m filtering_pipeline:\n",
      "File \u001b[1;32md:\\Users\\gabri\\anaconda3\\envs\\tf_p3.9\\lib\\site-packages\\pandas\\io\\parsers.py:610\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    605\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    606\u001b[0m     dialect, delimiter, delim_whitespace, engine, sep, defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m    607\u001b[0m )\n\u001b[0;32m    608\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 610\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32md:\\Users\\gabri\\anaconda3\\envs\\tf_p3.9\\lib\\site-packages\\pandas\\io\\parsers.py:468\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    465\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    467\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 468\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[1;32md:\\Users\\gabri\\anaconda3\\envs\\tf_p3.9\\lib\\site-packages\\pandas\\io\\parsers.py:1057\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1055\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, nrows\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1056\u001b[0m     nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m-> 1057\u001b[0m     index, columns, col_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[0;32m   1059\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1060\u001b[0m         \u001b[39mif\u001b[39;00m col_dict:\n\u001b[0;32m   1061\u001b[0m             \u001b[39m# Any column is actually fine:\u001b[39;00m\n",
      "File \u001b[1;32md:\\Users\\gabri\\anaconda3\\envs\\tf_p3.9\\lib\\site-packages\\pandas\\io\\parsers.py:2061\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2059\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, nrows\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2060\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2061\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[0;32m   2062\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m   2063\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_chunk:\n",
      "File \u001b[1;32mpandas\\_libs\\parsers.pyx:759\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\parsers.pyx:842\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\parsers.pyx:1943\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\Users\\gabri\\anaconda3\\envs\\tf_p3.9\\lib\\_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreadinto\u001b[39m(\u001b[39mself\u001b[39m, b):\n\u001b[0;32m     67\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b) \u001b[39mas\u001b[39;00m view, view\u001b[39m.\u001b[39mcast(\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m byte_view:\n\u001b[1;32m---> 68\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m(byte_view))\n\u001b[0;32m     69\u001b[0m         byte_view[:\u001b[39mlen\u001b[39m(data)] \u001b[39m=\u001b[39m data\n\u001b[0;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(data)\n",
      "File \u001b[1;32md:\\Users\\gabri\\anaconda3\\envs\\tf_p3.9\\lib\\gzip.py:495\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39m# Read a chunk of data from the file\u001b[39;00m\n\u001b[0;32m    493\u001b[0m buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread(io\u001b[39m.\u001b[39mDEFAULT_BUFFER_SIZE)\n\u001b[1;32m--> 495\u001b[0m uncompress \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decompressor\u001b[39m.\u001b[39;49mdecompress(buf, size)\n\u001b[0;32m    496\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39munconsumed_tail \u001b[39m!=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    497\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mprepend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39munconsumed_tail)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ckpt_path = f'checkpoints/test/test1'\n",
    "model = LSHModel(\n",
    "    k=5,\n",
    "    threshold=0.1,\n",
    "    num_hashes=100,\n",
    "    shingle_hash_bits=16,\n",
    "    track_shingles=True,\n",
    "    checkpoint_path=ckpt_path\n",
    ")\n",
    "\n",
    "num_docs = 100\n",
    "\n",
    "files = []\n",
    "data_path = DATA_PATH\n",
    "\n",
    "for name in os.listdir(data_path):\n",
    "    full_path = os.path.join(data_path, name)\n",
    "    if os.path.isfile(full_path):\n",
    "        files.append(full_path)\n",
    "\n",
    "duplicates = 0\n",
    "count = num_docs\n",
    "\n",
    "with tqdm(\n",
    "    total=num_docs,\n",
    "    desc='Adding documents to model',\n",
    "    leave=False\n",
    ") as pbar:\n",
    "    for file in files:\n",
    "        if count == 0:\n",
    "            break\n",
    "        \n",
    "        print(f'Reading file {file}')\n",
    "        df = pd.read_csv(\n",
    "            file, \n",
    "            compression='gzip', \n",
    "            index_col=0,\n",
    "            encoding='utf-8', \n",
    "            quoting=csv.QUOTE_ALL,\n",
    "            low_memory=False\n",
    "        )\n",
    "\n",
    "        df = df[df['language'] == 'en']\n",
    "\n",
    "        for filter_f in filtering_pipeline:\n",
    "            df['text'] = df['text'].apply(filter_f)\n",
    "\n",
    "        df_unique = df.drop_duplicates(subset=['text'])\n",
    "        duplicates += len(df) - len(df_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Tuples\n",
    "matrix = [('22', '34', '23'),\n",
    "         ('33', '31', '11'),\n",
    "         ('44', '16', '21'),\n",
    "         ('55', '32', '22'),\n",
    "         ('66', '33', '27'),\n",
    "         ('77', '35', '11')\n",
    "         ]\n",
    "# Create a DataFrame object\n",
    "dfObj = pd.DataFrame(matrix, columns=list('xyz'), index=list('abcdef'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>55</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>66</td>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>77</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x   y   z\n",
       "a  22  34  23\n",
       "b  33  31  11\n",
       "c  44  16  21\n",
       "d  55  32  22\n",
       "e  66  33  27\n",
       "f  77  35  11"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>55</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>66</td>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>77</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x   y   z\n",
       "a  22  34  23\n",
       "b  33  31  11\n",
       "c  44  16  21\n",
       "d  55  32  22\n",
       "e  66  33  27\n",
       "f  77  35  11"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfObj['z'] = dfObj['z'].apply(remove_https)\n",
    "dfObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ababss'"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_https('ababss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('tf_p3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "581cf1c8eaff79be0b011c62368efcaf64eb5b63193a1727e5f23ab81cee7c9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
